{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty\n"
     ]
    }
   ],
   "source": [
    "foo = 'Monty'\n",
    "bar = foo\n",
    "foo = 'Python'\n",
    "print(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], []]\n",
      "[['Python'], ['Python'], ['Python']]\n"
     ]
    }
   ],
   "source": [
    "empty = []\n",
    "nested = [empty, empty, empty]\n",
    "print(nested)\n",
    "\n",
    "nested[1].append('Python')\n",
    "print(nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 5\n",
    "python = ['Python']\n",
    "snake_nest = [python] * size\n",
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]\n",
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "position = random.choice(range(size))\n",
    "snake_nest[position] = ['Python']\n",
    "print(snake_nest)\n",
    "\n",
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]\n",
    "\n",
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2043845525768, 2043845525768, 2043845525768, 2043845525768, 2043845562440]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id(snake) for snake in snake_nest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "['dog']\n"
     ]
    }
   ],
   "source": [
    "mixed = ['cat', '', ['dog'], []]\n",
    "for element in mixed:\n",
    "     if element:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['No', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '.']\n",
    "all(len(w) > 4 for w in sent)\n",
    "\n",
    "any(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "('fem',)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " t = 'walk', 'fem', \n",
    "('walk', 'fem', 3)\n",
    "print(t[0])\n",
    "\n",
    "print(t[1:])\n",
    "\n",
    "len(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t the turned\n",
      "ute ['off', 'the', 'spectroroute'] (6, 'turned')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(29, 5, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'I turned off the spectroroute'\n",
    "text = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "pair = (6, 'turned')\n",
    "print(raw[2], text[3], pair[1])\n",
    "\n",
    "print(raw[-3:], text[-3:], pair[-3:])\n",
    "\n",
    "len(raw), len(text), len(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', 'Red', 'lorry', 'red', 'yellow']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'Red lorry, yellow lorry, red lorry, yellow lorry.'\n",
    "text = word_tokenize(raw)\n",
    "fdist = nltk.FreqDist(text)\n",
    "sorted(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red: 1;lorry: 4;,: 3;yellow: 2;red: 1;.: 1;"
     ]
    }
   ],
   "source": [
    "for  key in fdist:\n",
    "    print(key + ':', fdist[key], end= ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'noun'),\n",
       " ('turned', 'verb'),\n",
       " ('off', 'prep'),\n",
       " ('the', 'det'),\n",
       " ('spectroroute', 'noun')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "tags = ['noun', 'verb', 'prep', 'det', 'noun']\n",
    "zip(words, tags)\n",
    "list(zip(words, tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'I'), (1, 'turned'), (2, 'off'), (3, 'the'), (4, 'spectroroute')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.corpus.nps_chat.words()\n",
    "cut = int(0.9 * len(text))\n",
    "training_data, test_data = text[:cut], text[cut:]\n",
    "text == training_data + test_data\n",
    "len(training_data) / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 'I turned off the spectroroute'.split()\n",
    "wordlens = [(len(word), word) for word in words]\n",
    "wordlens.sort()\n",
    "' '. join(w for (_,w) in wordlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = [\n",
    "('the', 'det', ['Di:', 'D@']),\n",
    "('off', 'prep', ['Qf', 'O:f'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.sort()\n",
    "lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])\n",
    "del lexicon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'when',\n",
       " 'i',\n",
       " 'use',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " \"''\",\n",
       " 'humpty',\n",
       " 'dumpty',\n",
       " 'said',\n",
       " 'in',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'scornful',\n",
       " 'tone',\n",
       " ',',\n",
       " \"''\",\n",
       " 'it',\n",
       " 'means',\n",
       " 'just',\n",
       " 'what',\n",
       " 'i',\n",
       " 'choose',\n",
       " 'it',\n",
       " 'to',\n",
       " 'mean',\n",
       " '-',\n",
       " 'neither',\n",
       " 'more',\n",
       " 'nor',\n",
       " 'less',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " text = '''\"When I use a word,\" Humpty Dumpty said in rather a scornful tone,\n",
    "\"it means just what I choose it to mean - neither more nor less.\"'''\n",
    "[w.lower() for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([w.lower() for w in word_tokenize(text)])\n",
    "max(w.lower() for w in word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.corpus.brown.words(categories='news')\n",
    "count = 0\n",
    "total = 0\n",
    "for token in tokens:\n",
    "    count += 1\n",
    "    total += len(token)\n",
    "    total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.401545438271973\n"
     ]
    }
   ],
   "source": [
    "total = sum(len(t) for t in tokens)\n",
    "print(total / len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = sorted(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   5.40% the\n",
      "  2  10.42% ,\n",
      "  3  14.67% .\n",
      "  4  17.78% of\n",
      "  5  20.19% and\n",
      "  6  22.40% to\n",
      "  7  24.29% a\n",
      "  8  25.97% in\n"
     ]
    }
   ],
   "source": [
    "fd = nltk.FreqDist(nltk.corpus.brown.words())\n",
    "cumulative = 0.0\n",
    "most_common_words = [word for (word, count) in fd.most_common()]\n",
    "for rank, word in enumerate(most_common_words):\n",
    "     cumulative += fd.freq(word)\n",
    "     print(\"%3d %6.2f%% %s\" % (rank + 1, cumulative * 100, word))\n",
    "     if cumulative > 0.25:\n",
    "       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unextinguishable'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.corpus.gutenberg.words('milton-paradise.txt')\n",
    "longest = ''\n",
    "for word in text:\n",
    "    if len(word) > len(longest):\n",
    "         longest = word\n",
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unextinguishable',\n",
       " 'transubstantiate',\n",
       " 'inextinguishable',\n",
       " 'incomprehensible']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max(len(word) for word in text)\n",
    "[word for word in text if len(word) == maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave'],\n",
       " ['dog', 'gave', 'John'],\n",
       " ['gave', 'John', 'the'],\n",
       " ['John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = 3\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), {'Alice'}, set()]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "m, n = 3, 7\n",
    "array = [[set() for i in range(n)] for j in range(m)]\n",
    "array[2][5].add('Alice')\n",
    "pprint.pprint(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
      " [{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
      " [{7}, {7}, {7}, {7}, {7}, {7}, {7}]]\n"
     ]
    }
   ],
   "source": [
    "array = [[set()] * n] * m\n",
    "array[2][5].add(7)\n",
    "pprint.pprint(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_text(file):\n",
    "    \"\"\"Read text from a file, normalizing whitespace and stripping HTML markup.\"\"\"\n",
    "    text = open(file).read()\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def repeat(msg, num):  [1]\n",
    "    return ' '.join([msg] * num)\n",
    "monty = 'Monty Python'\n",
    "repeat(monty, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def monty():\n",
    "     return \"Monty Python\"\n",
    "monty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noun']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_up(word, properties):\n",
    "     word = 'lolcat'\n",
    "     properties.append('noun')\n",
    "     properties = 5\n",
    "\n",
    "w = ''\n",
    "p = []\n",
    "set_up(w, p)\n",
    "w\n",
    "''\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = ''\n",
    "word = w\n",
    "word = 'lolcat'\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noun']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = []\n",
    "properties = p\n",
    "properties.append('noun')\n",
    "properties = 5\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag(word):\n",
    "     if word in ['a', 'the', 'all']:\n",
    "         return 'det'\n",
    "     else:\n",
    "         return 'noun'\n",
    "\n",
    "tag('the')\n",
    "\n",
    "tag('knight')\n",
    "\n",
    "tag([\"'Tis\", 'but', 'a', 'scratch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "     assert isinstance(word, basestring), \"argument to tag() must be a string\"\n",
    "     if word in ['a', 'the', 'all']:\n",
    "         return 'det'\n",
    "     else:\n",
    "         return 'noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def freq_words(url, freqdist, n):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "    for word in word_tokenize(raw):\n",
    "        freqdist[word.lower()] += 1\n",
    "    result = []\n",
    "    for word, count in freqdist.most_common(n):\n",
    "        result = result + [word]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constitution = \"http://www.archives.gov/exhibits/charters/constitution_transcript.html\"\n",
    "fd = nltk.FreqDist()\n",
    "freq_words(constitution, fd, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def freq_words(url, n):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    text = BeautifulSoup(html, 'html.parser').get_text()\n",
    "    freqdist = nltk.FreqDist(word.lower() for word in word_tokenize(text))\n",
    "    return [word for (word, _) in fd.most_common(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(reference, test):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of test items that equal the corresponding reference items.\n",
    "\n",
    "    Given a list of reference values and a corresponding list of test values,\n",
    "    return the fraction of corresponding values that are equal.\n",
    "    In particular, return the fraction of indexes\n",
    "    {0<i<=len(test)} such that C{test[i] == reference[i]}.\n",
    "\n",
    "        >>> accuracy(['ADJ', 'N', 'V', 'N'], ['N', 'N', 'V', 'ADJ'])\n",
    "        0.5\n",
    "\n",
    "    :param reference: An ordered list of reference values\n",
    "    :type reference: list\n",
    "    :param test: A list of values to compare against the corresponding\n",
    "        reference values\n",
    "    :type test: list\n",
    "    :return: the accuracy score\n",
    "    :rtype: float\n",
    "    :raises ValueError: If reference and length do not have the same length\n",
    "    \"\"\"\n",
    "\n",
    "    if len(reference) != len(test):\n",
    "        raise ValueError(\"Lists must have the same length.\")\n",
    "    num_correct = 0\n",
    "    for x, y in zip(reference, test):\n",
    "        if x == y:\n",
    "            num_correct += 1\n",
    "    return float(num_correct) / len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's', '.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the',\n",
    "         'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']\n",
    "def extract_property(prop):\n",
    "     return [prop(word) for word in sent]\n",
    "\n",
    "extract_property(len)\n",
    "def last_letter(word):\n",
    "     return word[-1]\n",
    "extract_property(last_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's', '.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(lambda w: w[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " 'Take',\n",
       " 'and',\n",
       " 'care',\n",
       " 'care',\n",
       " 'of',\n",
       " 'of',\n",
       " 'sense',\n",
       " 'sounds',\n",
       " 'take',\n",
       " 'the',\n",
       " 'the',\n",
       " 'themselves',\n",
       " 'will']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search1(substring, words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "def search2(substring, words):\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza "
     ]
    }
   ],
   "source": [
    "for item in search1('zz', nltk.corpus.brown.words()):\n",
    "    print(item, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza "
     ]
    }
   ],
   "source": [
    "for item in search2('zz', nltk.corpus.brown.words()):\n",
    "     print(item, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['police', 'fish', 'buffalo'],\n",
       " ['fish', 'police', 'buffalo'],\n",
       " ['fish', 'buffalo', 'police'],\n",
       " ['police', 'buffalo', 'fish'],\n",
       " ['buffalo', 'police', 'fish'],\n",
       " ['buffalo', 'fish', 'police']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def permutations(seq):\n",
    "     if len(seq) <= 1:\n",
    "         yield seq\n",
    "     else:\n",
    "         for perm in permutations(seq[1:]):\n",
    "             for i in range(len(perm)+1):\n",
    "                 yield perm[:i] + seq[0:1] + perm[i:]\n",
    "\n",
    "list(permutations(['police', 'fish', 'buffalo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_content_word(word):\n",
    "     return word.lower() not in ['a', 'of', 'the', 'and', 'will', ',', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the',\n",
    "         'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']\n",
    "list(filter(is_content_word, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent if is_content_word(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = list(map(len, nltk.corpus.brown.sents(categories='news')))\n",
    "sum(lengths) / len(lengths)\n",
    "lengths = [len(sent) for sent in nltk.corpus.brown.sents(categories='news')]\n",
    "\n",
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AliceAliceAliceAliceAlice'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repeat(msg='<empty>', num=1):\n",
    "     return msg * num\n",
    "repeat(num=3)\n",
    "\n",
    "repeat(msg='Alice')\n",
    "\n",
    "\n",
    "repeat(num=5, msg='Alice')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'African swallow')\n",
      "{'monty': 'python'}\n"
     ]
    }
   ],
   "source": [
    "def generic(*args, **kwargs):\n",
    "     print(args)\n",
    "     print(kwargs)\n",
    "\n",
    "generic(1, \"African swallow\", monty=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'French', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = [['four', 'calling', 'birds'],\n",
    "         ['three', 'French', 'hens'],\n",
    "         ['two', 'turtle', 'doves']]\n",
    "list(zip(song[0], song[1], song[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'French', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(file, min=1, num=10):\n",
    "     text = open(file).read()\n",
    "     tokens = word_tokenize(text)\n",
    "     freqdist = nltk.FreqDist(t for t in tokens if len(t) >= min)\n",
    "     return freqdist.most_common(num)\n",
    "fw = freq_words('ch01.rst', 4, 10)\n",
    "fw = freq_words('ch01.rst', min=4, num=10)\n",
    "fw = freq_words('ch01.rst', num=10, min=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-70-2cd2d0c7f838>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-70-2cd2d0c7f838>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    if verbose: print(\"Opening\", file)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def freq_words(file, min=1, num=10, verbose=False):\n",
    "    freqdist = FreqDist()\n",
    "     if verbose: print(\"Opening\", file)\n",
    "     text = open(file).read()\n",
    "     if verbose: print(\"Read in %d characters\" % len(file))\n",
    "     for word in word_tokenize(text):\n",
    "         if len(word) >= min:\n",
    "             freqdist[word] += 1\n",
    "             if verbose and freqdist.N() % 100 == 0: print(\".\", sep=\"\")\n",
    "     if verbose: print\n",
    "     return freqdist.most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial1(n):\n",
    "     result = 1\n",
    "     for i in range(n):\n",
    "         result *= (i+1)\n",
    "     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial2(n):\n",
    "     if n == 1:\n",
    "         return 1\n",
    "     else:\n",
    "         return n * factorial2(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size1(s):\n",
    "     return 1 + sum(size1(child) for child in s.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size2(s):\n",
    "     layer = [s] [1]\n",
    "     total = 0\n",
    "     while layer:\n",
    "         total += len(layer) [2]\n",
    "         layer = [h for c in layer for h in c.hyponyms()] [3]\n",
    "     return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "dog = wn.synset('dog.n.01')\n",
    "size1(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': {'h': {'a': {'i': {'r': {'value': 'flesh'}},\n",
      "                   't': {'value': 'cat'}},\n",
      "             'i': {'c': {'value': 'stylish'},\n",
      "                   'e': {'n': {'value': 'dog'}}}}}}\n"
     ]
    }
   ],
   "source": [
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value\n",
    " \t\n",
    "trie = {}\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "trie = dict(trie)              \n",
    "trie['c']['h']['a']['t']['value']\n",
    "'cat'\n",
    "pprint.pprint(trie, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Index...\n",
      "query> hello how is the weather\n",
      "Not found\n",
      "query> A\n",
      "Not found\n",
      "query> a man\n",
      "Not found\n"
     ]
    }
   ],
   "source": [
    "def raw(file):\n",
    "    contents = open(file).read()\n",
    "    contents = re.sub(r'<.*?>', ' ', contents)\n",
    "    contents = re.sub('\\s+', ' ', contents)\n",
    "    return contents\n",
    "\n",
    "def snippet(doc, term):\n",
    "    text = ' '*30 + raw(doc) + ' '*30\n",
    "    pos = text.index(term)\n",
    "    return text[pos-30:pos+30]\n",
    "\n",
    "print(\"Building Index...\")\n",
    "files = nltk.corpus.movie_reviews.abspaths()\n",
    "idx = nltk.Index((w, f) for f in files for w in raw(f).split())\n",
    "\n",
    "query = ''\n",
    "while query != \"quit\":\n",
    "    query = input(\"query> \")     # use raw_input() in Python 2\n",
    "    if query in idx:\n",
    "        for doc in idx[query]:\n",
    "            print(snippet(doc, query))\n",
    "    else:\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tagged_corpus):\n",
    "    words = set()\n",
    "    tags = set()\n",
    "    for sent in tagged_corpus:\n",
    "        for word, tag in sent:\n",
    "            words.add(word)\n",
    "            tags.add(tag)\n",
    "    wm = dict((w, i) for (i, w) in enumerate(words))\n",
    "    tm = dict((t, i) for (i, t) in enumerate(tags))\n",
    "    return [[(wm[w], tm[t]) for (w, t) in sent] for sent in tagged_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import Timer\n",
    "vocab_size = 100000\n",
    "setup_list = \"import random; vocab = range(%d)\" % vocab_size [1]\n",
    "setup_set = \"import random; vocab = set(range(%d))\" % vocab_size [2]\n",
    "statement = \"random.randint(0, %d) in vocab\" % (vocab_size * 2) [3]\n",
    "print(Timer(statement, setup_list).timeit(1000))\n",
    "\n",
    "print(Timer(statement, setup_set).timeit(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def virahanka1(n):\n",
    "    if n == 0:\n",
    "        return [\"\"]\n",
    "    elif n == 1:\n",
    "        return [\"S\"]\n",
    "    else:\n",
    "        s = [\"S\" + prosody for prosody in virahanka1(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka1(n-2)]\n",
    "        return s + l\n",
    "\n",
    "def virahanka2(n):\n",
    "    lookup = [[\"\"], [\"S\"]]\n",
    "    for i in range(n-1):\n",
    "        s = [\"S\" + prosody for prosody in lookup[i+1]]\n",
    "        l = [\"L\" + prosody for prosody in lookup[i]]\n",
    "        lookup.append(s + l)\n",
    "    return lookup[n]\n",
    "\n",
    "def virahanka3(n, lookup={0:[\"\"], 1:[\"S\"]}):\n",
    "    if n not in lookup:\n",
    "        s = [\"S\" + prosody for prosody in virahanka3(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka3(n-2)]\n",
    "        lookup[n] = s + l\n",
    "    return lookup[n]\n",
    "\n",
    "from nltk import memoize\n",
    "@memoize\n",
    "def virahanka4(n):\n",
    "    if n == 0:\n",
    "        return [\"\"]\n",
    "    elif n == 1:\n",
    "        return [\"S\"]\n",
    "    else:\n",
    "        s = [\"S\" + prosody for prosody in virahanka4(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka4(n-2)]\n",
    "        return s + l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virahanka1(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "from matplotlib import pyplot\n",
    "\n",
    "colors = 'rgbcmyk' # red, green, blue, cyan, magenta, yellow, black\n",
    "\n",
    "def bar_chart(categories, words, counts):\n",
    "    \"Plot a bar chart showing counts for each word by category\"\n",
    "    ind = arange(len(words))\n",
    "    width = 1 / (len(categories) + 1)\n",
    "    bar_groups = []\n",
    "    for c in range(len(categories)):\n",
    "        bars = pyplot.bar(ind+c*width, counts[categories[c]], width,\n",
    "                         color=colors[c % len(colors)])\n",
    "        bar_groups.append(bars)\n",
    "    pyplot.xticks(ind+width, words)\n",
    "    pyplot.legend([b[0] for b in bar_groups], categories, loc='upper left')\n",
    "    pyplot.ylabel('Frequency')\n",
    "    pyplot.title('Frequency of Six Modal Verbs by Genre')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "genres = ['news', 'religion', 'hobbies', 'government', 'adventure']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "cfdist = nltk.ConditionalFreqDist(\n",
    "              (genre, word)\n",
    "              for genre in genres\n",
    "              for word in nltk.corpus.brown.words(categories=genre)\n",
    "              if word in modals)\n",
    "\n",
    "counts = {}\n",
    "for genre in genres:\n",
    "     counts[genre] = [cfdist[genre][word] for word in modals]\n",
    "bar_chart(genres, modals, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Type: text/html\n",
      "\n",
      "<html><body>\n",
      "<img src=\"modals.png\"/>\n",
      "</body></html>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import use, pyplot\n",
    "use('Agg')\n",
    "pyplot.savefig('modals.png') \n",
    "print('Content-Type: text/html')\n",
    "print()\n",
    "print('<html><body>')\n",
    "print('<img src=\"modals.png\"/>')\n",
    "print('</body></html>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def traverse(graph, start, node):\n",
    "    graph.depth[node.name] = node.shortest_path_distance(start)\n",
    "    for child in node.hyponyms():\n",
    "        graph.add_edge(node.name, child.name)\n",
    "        traverse(graph, start, child) \n",
    "\n",
    "def hyponym_graph(start):\n",
    "    G = nx.Graph() \n",
    "    G.depth = {}\n",
    "    traverse(G, start, start)\n",
    "    return G\n",
    "\n",
    "def graph_draw(graph):\n",
    "    nx.draw_graphviz(graph,\n",
    "         node_size = [16 * graph.degree(n) for n in graph],\n",
    "         node_color = [graph.depth[n] for n in graph],\n",
    "         with_labels = False)\n",
    "    matplotlib.pyplot.show()\n",
    " \t\n",
    "dog = wn.synset('dog.n.01')\n",
    "graph = hyponym_graph(dog)\n",
    "graph_draw(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "input_file = open(\"lexicon.csv\", \"rb\")\n",
    "for row in csv.reader(input_file): \n",
    "     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7, 8],\n",
       "       [6, 7, 8],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "cube = array([ [[0,0,0], [1,1,1], [2,2,2]],\n",
    "                [[3,3,3], [4,4,4], [5,5,5]],\n",
    "                [[6,6,6], [7,7,7], [8,8,8]] ])\n",
    "cube[1,1,1]\n",
    "\n",
    "cube[2].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4472136 , -0.89442719],\n",
       "       [-0.89442719,  0.4472136 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import linalg\n",
    "a=array([[4,0], [3,-5]])\n",
    "u,s,vt = linalg.svd(a)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
