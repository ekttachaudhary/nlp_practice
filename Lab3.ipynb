{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode(\"utf-8\")\n",
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176967"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(raw)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257727"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PART',\n",
       " 'I',\n",
       " 'CHAPTER',\n",
       " 'I',\n",
       " 'On',\n",
       " 'an',\n",
       " 'exceptionally',\n",
       " 'hot',\n",
       " 'evening',\n",
       " 'early',\n",
       " 'in',\n",
       " 'July',\n",
       " 'a',\n",
       " 'young',\n",
       " 'man',\n",
       " 'came',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'garret',\n",
       " 'in',\n",
       " 'which',\n",
       " 'he',\n",
       " 'lodged',\n",
       " 'in',\n",
       " 'S.',\n",
       " 'Place',\n",
       " 'and',\n",
       " 'walked',\n",
       " 'slowly',\n",
       " ',',\n",
       " 'as',\n",
       " 'though',\n",
       " 'in',\n",
       " 'hesitation',\n",
       " ',',\n",
       " 'towards',\n",
       " 'K.',\n",
       " 'bridge',\n",
       " '.']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1019:1059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5336"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find(\"PART I\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.rfind(\"End of Project Gutenberg's Crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195769"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw= raw[5338:1157743]\n",
    "raw.find(\"PART I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = request.urlopen(url).read().decode('utf-8')\n",
    "html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html.parser']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup('html.parser').get_text()\n",
    "tokens = word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokens = tokens[110:390]\n",
    "text = nltk.Text(tokens)\n",
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Language Log'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feedparser\n",
    "llog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\")\n",
    "llog['feed']['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llog.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modeling'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = llog.entries[5]\n",
    "post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = post.content[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>The current <a href=\"https://xkcd.com/2323/\" rel=\"noopener noreferr'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'current',\n",
       " 'xkcd',\n",
       " ':',\n",
       " 'Mouseover',\n",
       " 'title',\n",
       " ':',\n",
       " '``',\n",
       " 'You',\n",
       " \"'ve\",\n",
       " 'got',\n",
       " 'questions',\n",
       " ',',\n",
       " 'we',\n",
       " \"'ve\",\n",
       " 'got',\n",
       " 'assumptions',\n",
       " '.',\n",
       " \"''\",\n",
       " 'But',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'unfair',\n",
       " ',',\n",
       " 'in',\n",
       " 'my',\n",
       " 'opinion',\n",
       " ',',\n",
       " 'to',\n",
       " 'suggest',\n",
       " 'that',\n",
       " 'models',\n",
       " 'never',\n",
       " 'provide',\n",
       " 'answers',\n",
       " '.']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = BeautifulSoup(content, 'html.parser').get_text()\n",
    "word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from local files\n",
    "f = open('document.txt')\n",
    "raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, from the other side.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Desktop\\ml-course\\sample_project\\env\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "f = open('document.txt', 'rU')\n",
    "for line in f:\n",
    "    print(line.strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Desktop\\ml-course\\sample_project\\env\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "path = nltk.data.find('corpora/gutenberg/melville-moby_dick.txt')\n",
    "raw = open(path, 'rU').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = open('document.txt').read()\n",
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [w.lower() for w in tokens]\n",
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(words))\n",
    "type(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-207-9b21c932c920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'blog'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'blog'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "vocab.append('blog')\n",
    "raw.append('blog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-67c1a27cd064>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Who knows?'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbeatles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'john'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'paul'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'george'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ringo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mquery\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbeatles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not list"
     ]
    }
   ],
   "source": [
    "query = 'Who knows?'\n",
    "beatles = ['john', 'paul', 'george', 'ringo']\n",
    "query + beatles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Strings: Text Processing at the lowest level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty Python\n",
      "Monty Python's Flying Circus\n",
      "Monty Python's Flying Circus\n"
     ]
    }
   ],
   "source": [
    "monty = 'Monty Python'\n",
    "print(monty)\n",
    "\n",
    "circus = \"Monty Python's Flying Circus\"\n",
    "print(circus)\n",
    "\n",
    "circus = 'Monty Python\\'s Flying Circus'\n",
    "print(circus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a Summer's day?Thou are more lovely and more temperate:\n",
      "Rough winds do shake the darling buds of May,And Summer's lease hath all too short a date:\n"
     ]
    }
   ],
   "source": [
    "couplet = \"Shall I compare thee to a Summer's day?\"\\\n",
    "           \"Thou are more lovely and more temperate:\"\n",
    "print(couplet)\n",
    "\n",
    "couplet = (\"Rough winds do shake the darling buds of May,\"\n",
    "          \"And Summer's lease hath all too short a date:\")\n",
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            very\n",
      "          veryvery\n",
      "        veryveryvery\n",
      "      veryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "veryveryveryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "      veryveryveryvery\n",
      "        veryveryvery\n",
      "          veryvery\n",
      "            very\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]\n",
    "b = [' ' * 2 * (7 - i) + 'very' * i for i in a]\n",
    "for line in b:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty PythonHoly Grail\n",
      "Monty Python Holy Grail\n",
      "Monty Python and the Holy Grail\n"
     ]
    }
   ],
   "source": [
    "grail = 'Holy Grail'\n",
    "print(monty + grail)\n",
    "print(monty, grail)\n",
    "print(monty, \"and the\", grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c o l o r l e s s   g r e e n   i d e a s   s l e e p   f u r i o u s l y "
     ]
    }
   ],
   "source": [
    "sent = 'colorless green ideas sleep furiously'\n",
    "for char in sent:\n",
    "    print(char, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "raw = gutenberg.raw('melville-moby_dick.txt')\n",
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "fdist.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e',\n",
       " 't',\n",
       " 'a',\n",
       " 'o',\n",
       " 'n',\n",
       " 'i',\n",
       " 's',\n",
       " 'h',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " 'u',\n",
       " 'm',\n",
       " 'c',\n",
       " 'w',\n",
       " 'f',\n",
       " 'g',\n",
       " 'p',\n",
       " 'b',\n",
       " 'y',\n",
       " 'v',\n",
       " 'k',\n",
       " 'q',\n",
       " 'j',\n",
       " 'x',\n",
       " 'z']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char for (char, count) in fdist.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pyth'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[6:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[-12:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found \"thing\"\n"
     ]
    }
   ],
   "source": [
    "phrase = 'And now for something completely different'\n",
    "if 'thing' in phrase:\n",
    "    print('found \"thing\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.find('Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'Paul', 'George', 'Ringo', 'Brian']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Who knows?'\n",
    "beatles = ['John', 'Paul', 'George', 'Ringo']\n",
    "query[2]\n",
    "beatles[2]\n",
    "query[:2]\n",
    "beatles[:2]\n",
    "beatles + ['Brian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = nltk.data.find('corpora/unicode_samples/polish-lat2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruska Biblioteka Państwowa. Jej dawne zbiory znane pod nazwą\n",
      "\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\n",
      "Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały\n",
      "odnalezione po 1945 r. na terytorium Polski. Trafiły do Biblioteki\n",
      "Jagiellońskiej w Krakowie, obejmują ponad 500 tys. zabytkowych\n",
      "archiwaliów, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\n"
     ]
    }
   ],
   "source": [
    "f = open(path, encoding='latin2')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Pruska Biblioteka Pa\\\\u0144stwowa. Jej dawne zbiory znane pod nazw\\\\u0105'\n",
      "b'\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez'\n",
      "b'Niemc\\\\xf3w pod koniec II wojny \\\\u015bwiatowej na Dolny \\\\u015al\\\\u0105sk, zosta\\\\u0142y'\n",
      "b'odnalezione po 1945 r. na terytorium Polski. Trafi\\\\u0142y do Biblioteki'\n",
      "b'Jagiello\\\\u0144skiej w Krakowie, obejmuj\\\\u0105 ponad 500 tys. zabytkowych'\n",
      "b'archiwali\\\\xf3w, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.'\n"
     ]
    }
   ],
   "source": [
    "f = open(path, encoding='latin2')\n",
    "for line in f:\n",
    "     line = line.strip()\n",
    "     print(line.encode('unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abaissed',\n",
       " 'abandoned',\n",
       " 'abased',\n",
       " 'abashed',\n",
       " 'abatised',\n",
       " 'abed',\n",
       " 'aborted',\n",
       " 'abridged',\n",
       " 'abscessed',\n",
       " 'absconded',\n",
       " 'absorbed',\n",
       " 'abstracted',\n",
       " 'abstricted',\n",
       " 'accelerated',\n",
       " 'accepted',\n",
       " 'accidented',\n",
       " 'accoladed',\n",
       " 'accolated',\n",
       " 'accomplished',\n",
       " 'accosted',\n",
       " 'accredited',\n",
       " 'accursed',\n",
       " 'accused',\n",
       " 'accustomed',\n",
       " 'acetated',\n",
       " 'acheweed',\n",
       " 'aciculated',\n",
       " 'aciliated',\n",
       " 'acknowledged',\n",
       " 'acorned',\n",
       " 'acquainted',\n",
       " 'acquired',\n",
       " 'acquisited',\n",
       " 'acred',\n",
       " 'aculeated',\n",
       " 'addebted',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addlebrained',\n",
       " 'addleheaded',\n",
       " 'addlepated',\n",
       " 'addorsed',\n",
       " 'adempted',\n",
       " 'adfected',\n",
       " 'adjoined',\n",
       " 'admired',\n",
       " 'admitted',\n",
       " 'adnexed',\n",
       " 'adopted',\n",
       " 'adossed',\n",
       " 'adreamed',\n",
       " 'adscripted',\n",
       " 'aduncated',\n",
       " 'advanced',\n",
       " 'advised',\n",
       " 'aeried',\n",
       " 'aethered',\n",
       " 'afeared',\n",
       " 'affected',\n",
       " 'affectioned',\n",
       " 'affined',\n",
       " 'afflicted',\n",
       " 'affricated',\n",
       " 'affrighted',\n",
       " 'affronted',\n",
       " 'aforenamed',\n",
       " 'afterfeed',\n",
       " 'aftershafted',\n",
       " 'afterthoughted',\n",
       " 'afterwitted',\n",
       " 'agazed',\n",
       " 'aged',\n",
       " 'agglomerated',\n",
       " 'aggrieved',\n",
       " 'agminated',\n",
       " 'agnamed',\n",
       " 'agonied',\n",
       " 'agreed',\n",
       " 'agueweed',\n",
       " 'ahungered',\n",
       " 'aiguilletted',\n",
       " 'ailweed',\n",
       " 'airbrained',\n",
       " 'airified',\n",
       " 'aiseweed',\n",
       " 'aisled',\n",
       " 'alarmed',\n",
       " 'alated',\n",
       " 'alimonied',\n",
       " 'aliped',\n",
       " 'alleyed',\n",
       " 'allied',\n",
       " 'alligatored',\n",
       " 'allseed',\n",
       " 'almsdeed',\n",
       " 'aloed',\n",
       " 'altared',\n",
       " 'alveolated',\n",
       " 'amazed',\n",
       " 'ameed',\n",
       " 'amiced',\n",
       " 'amphitheatered',\n",
       " 'ampullated',\n",
       " 'amused',\n",
       " 'anchored',\n",
       " 'angled',\n",
       " 'anguiped',\n",
       " 'anguished',\n",
       " 'angulated',\n",
       " 'angulinerved',\n",
       " 'anhungered',\n",
       " 'animated',\n",
       " 'aniseed',\n",
       " 'annodated',\n",
       " 'annulated',\n",
       " 'anomaliped',\n",
       " 'anserated',\n",
       " 'anteflected',\n",
       " 'anteflexed',\n",
       " 'antimoniated',\n",
       " 'antimoniureted',\n",
       " 'antimoniuretted',\n",
       " 'antiquated',\n",
       " 'antired',\n",
       " 'antiweed',\n",
       " 'antlered',\n",
       " 'apertured',\n",
       " 'apexed',\n",
       " 'apicifixed',\n",
       " 'apiculated',\n",
       " 'apocopated',\n",
       " 'apostrophied',\n",
       " 'appearanced',\n",
       " 'appellatived',\n",
       " 'appendaged',\n",
       " 'appendiculated',\n",
       " 'applied',\n",
       " 'appressed',\n",
       " 'aralkylated',\n",
       " 'arbored',\n",
       " 'arched',\n",
       " 'architraved',\n",
       " 'arcked',\n",
       " 'arcuated',\n",
       " 'ared',\n",
       " 'areolated',\n",
       " 'ariled',\n",
       " 'arillated',\n",
       " 'armchaired',\n",
       " 'armed',\n",
       " 'armied',\n",
       " 'armillated',\n",
       " 'armored',\n",
       " 'armoried',\n",
       " 'arpeggiated',\n",
       " 'arpeggioed',\n",
       " 'arrased',\n",
       " 'arrowed',\n",
       " 'arrowheaded',\n",
       " 'arrowweed',\n",
       " 'arseneted',\n",
       " 'arsenetted',\n",
       " 'arseniureted',\n",
       " 'articled',\n",
       " 'articulated',\n",
       " 'ashamed',\n",
       " 'ashlared',\n",
       " 'ashweed',\n",
       " 'aspersed',\n",
       " 'asphyxied',\n",
       " 'assented',\n",
       " 'assessed',\n",
       " 'assigned',\n",
       " 'assistanted',\n",
       " 'associated',\n",
       " 'assonanced',\n",
       " 'assorted',\n",
       " 'assumed',\n",
       " 'assured',\n",
       " 'asteriated',\n",
       " 'astonied',\n",
       " 'aswooned',\n",
       " 'atrophiated',\n",
       " 'atrophied',\n",
       " 'attached',\n",
       " 'attired',\n",
       " 'attrited',\n",
       " 'augmented',\n",
       " 'aurated',\n",
       " 'auricled',\n",
       " 'auriculated',\n",
       " 'authorized',\n",
       " 'autoinhibited',\n",
       " 'autosensitized',\n",
       " 'autosled',\n",
       " 'averted',\n",
       " 'avowed',\n",
       " 'awearied',\n",
       " 'awned',\n",
       " 'awninged',\n",
       " 'axed',\n",
       " 'axhammered',\n",
       " 'axised',\n",
       " 'axled',\n",
       " 'axseed',\n",
       " 'axweed',\n",
       " 'azoted',\n",
       " 'azured',\n",
       " 'babied',\n",
       " 'babished',\n",
       " 'babyfied',\n",
       " 'baccated',\n",
       " 'backboned',\n",
       " 'backed',\n",
       " 'backhanded',\n",
       " 'backwatered',\n",
       " 'baconweed',\n",
       " 'badgerweed',\n",
       " 'bagged',\n",
       " 'bagwigged',\n",
       " 'baked',\n",
       " 'balanced',\n",
       " 'balconied',\n",
       " 'baldachined',\n",
       " 'baldricked',\n",
       " 'balled',\n",
       " 'ballweed',\n",
       " 'balsamweed',\n",
       " 'balustered',\n",
       " 'balustraded',\n",
       " 'bandannaed',\n",
       " 'banded',\n",
       " 'bandoleered',\n",
       " 'bangled',\n",
       " 'banked',\n",
       " 'bankweed',\n",
       " 'bannered',\n",
       " 'barbated',\n",
       " 'barbed',\n",
       " 'barebacked',\n",
       " 'bareboned',\n",
       " 'barefaced',\n",
       " 'barefooted',\n",
       " 'barehanded',\n",
       " 'bareheaded',\n",
       " 'barelegged',\n",
       " 'barenecked',\n",
       " 'barmybrained',\n",
       " 'barred',\n",
       " 'barreled',\n",
       " 'bartizaned',\n",
       " 'basebred',\n",
       " 'based',\n",
       " 'basehearted',\n",
       " 'basifixed',\n",
       " 'basilweed',\n",
       " 'basined',\n",
       " 'basinerved',\n",
       " 'basqued',\n",
       " 'bastioned',\n",
       " 'bated',\n",
       " 'bathroomed',\n",
       " 'battered',\n",
       " 'batteried',\n",
       " 'battled',\n",
       " 'battlemented',\n",
       " 'bayed',\n",
       " 'bayoneted',\n",
       " 'beached',\n",
       " 'beaded',\n",
       " 'beaked',\n",
       " 'bealtared',\n",
       " 'beamed',\n",
       " 'beanweed',\n",
       " 'beaproned',\n",
       " 'bearded',\n",
       " 'beautied',\n",
       " 'beavered',\n",
       " 'beballed',\n",
       " 'bebannered',\n",
       " 'bebed',\n",
       " 'bebelted',\n",
       " 'bebled',\n",
       " 'bebothered',\n",
       " 'bebouldered',\n",
       " 'bebuttoned',\n",
       " 'becassocked',\n",
       " 'bechained',\n",
       " 'bechignoned',\n",
       " 'becircled',\n",
       " 'becoiffed',\n",
       " 'becombed',\n",
       " 'becousined',\n",
       " 'becrinolined',\n",
       " 'becuffed',\n",
       " 'becurtained',\n",
       " 'becushioned',\n",
       " 'bed',\n",
       " 'bedaggered',\n",
       " 'bedangled',\n",
       " 'bedded',\n",
       " 'bediademed',\n",
       " 'bediamonded',\n",
       " 'beedged',\n",
       " 'beefheaded',\n",
       " 'beeheaded',\n",
       " 'beeswinged',\n",
       " 'beetled',\n",
       " 'beetleheaded',\n",
       " 'beetleweed',\n",
       " 'beeweed',\n",
       " 'befamilied',\n",
       " 'befanned',\n",
       " 'befathered',\n",
       " 'beferned',\n",
       " 'befetished',\n",
       " 'befezzed',\n",
       " 'befilleted',\n",
       " 'befilmed',\n",
       " 'beforested',\n",
       " 'befountained',\n",
       " 'befrocked',\n",
       " 'befrogged',\n",
       " 'befurbelowed',\n",
       " 'befurred',\n",
       " 'begabled',\n",
       " 'begarlanded',\n",
       " 'begartered',\n",
       " 'beggarweed',\n",
       " 'beglobed',\n",
       " 'begoggled',\n",
       " 'begowned',\n",
       " 'behatted',\n",
       " 'behaviored',\n",
       " 'beheadlined',\n",
       " 'behooped',\n",
       " 'beinked',\n",
       " 'bekilted',\n",
       " 'beknived',\n",
       " 'beknotted',\n",
       " 'belaced',\n",
       " 'belated',\n",
       " 'belatticed',\n",
       " 'belavendered',\n",
       " 'beledgered',\n",
       " 'belfried',\n",
       " 'beliked',\n",
       " 'belimousined',\n",
       " 'belled',\n",
       " 'bellied',\n",
       " 'bellmouthed',\n",
       " 'bellweed',\n",
       " 'beloved',\n",
       " 'belozenged',\n",
       " 'belted',\n",
       " 'bemazed',\n",
       " 'bemedaled',\n",
       " 'bemedalled',\n",
       " 'bemitered',\n",
       " 'bemitred',\n",
       " 'bemused',\n",
       " 'bemuslined',\n",
       " 'bended',\n",
       " 'beneaped',\n",
       " 'beneficed',\n",
       " 'beneighbored',\n",
       " 'benempted',\n",
       " 'benighted',\n",
       " 'bennetweed',\n",
       " 'benumbed',\n",
       " 'benweed',\n",
       " 'benzoated',\n",
       " 'benzoinated',\n",
       " 'bepastured',\n",
       " 'bepatched',\n",
       " 'beperiwigged',\n",
       " 'bepewed',\n",
       " 'bepillared',\n",
       " 'bepistoled',\n",
       " 'beplaided',\n",
       " 'beplumed',\n",
       " 'beribanded',\n",
       " 'beribboned',\n",
       " 'beringed',\n",
       " 'beringleted',\n",
       " 'berobed',\n",
       " 'berouged',\n",
       " 'berried',\n",
       " 'berthed',\n",
       " 'beruffed',\n",
       " 'beruffled',\n",
       " 'beshawled',\n",
       " 'besieged',\n",
       " 'beslushed',\n",
       " 'besotted',\n",
       " 'bespecked',\n",
       " 'bespectacled',\n",
       " 'besped',\n",
       " 'bespeed',\n",
       " 'bespelled',\n",
       " 'bespurred',\n",
       " 'bestatued',\n",
       " 'bestayed',\n",
       " 'bestrapped',\n",
       " 'bestubbled',\n",
       " 'besweatered',\n",
       " 'betattered',\n",
       " 'betaxed',\n",
       " 'betowered',\n",
       " 'betrothed',\n",
       " 'betrousered',\n",
       " 'betted',\n",
       " 'betuckered',\n",
       " 'beturbaned',\n",
       " 'betusked',\n",
       " 'betutored',\n",
       " 'betwattled',\n",
       " 'beuniformed',\n",
       " 'beveled',\n",
       " 'bevelled',\n",
       " 'bevesseled',\n",
       " 'bevesselled',\n",
       " 'bevined',\n",
       " 'bevoiled',\n",
       " 'bewaitered',\n",
       " 'bewhiskered',\n",
       " 'bewigged',\n",
       " 'bewildered',\n",
       " 'bewinged',\n",
       " 'bewired',\n",
       " 'bewrathed',\n",
       " 'biangulated',\n",
       " 'biarcuated',\n",
       " 'biarticulated',\n",
       " 'bicarbureted',\n",
       " 'biciliated',\n",
       " 'bicolored',\n",
       " 'bicorned',\n",
       " 'bidented',\n",
       " 'bifanged',\n",
       " 'bifidated',\n",
       " 'biflected',\n",
       " 'biforked',\n",
       " 'biformed',\n",
       " 'bifronted',\n",
       " 'bifurcated',\n",
       " 'bigeminated',\n",
       " 'bighearted',\n",
       " 'bigmouthed',\n",
       " 'bigoted',\n",
       " 'bigwigged',\n",
       " 'bilamellated',\n",
       " 'bilaminated',\n",
       " 'billed',\n",
       " 'bilobated',\n",
       " 'bilobed',\n",
       " 'bilsted',\n",
       " 'bimaculated',\n",
       " 'bimotored',\n",
       " 'bindweed',\n",
       " 'bineweed',\n",
       " 'binominated',\n",
       " 'binucleated',\n",
       " 'biparted',\n",
       " 'bipectinated',\n",
       " 'biped',\n",
       " 'bipennated',\n",
       " 'bipinnated',\n",
       " 'bipinnatiparted',\n",
       " 'bipinnatisected',\n",
       " 'biradiated',\n",
       " 'birdmouthed',\n",
       " 'birdseed',\n",
       " 'birdweed',\n",
       " 'birostrated',\n",
       " 'birthbed',\n",
       " 'bisexed',\n",
       " 'bishopweed',\n",
       " 'bistered',\n",
       " 'bistipuled',\n",
       " 'bisubstituted',\n",
       " 'bitted',\n",
       " 'bitterhearted',\n",
       " 'bitterweed',\n",
       " 'bituberculated',\n",
       " 'bitumed',\n",
       " 'bivalved',\n",
       " 'bivaulted',\n",
       " 'bivocalized',\n",
       " 'blackhearted',\n",
       " 'blackseed',\n",
       " 'blackshirted',\n",
       " 'bladderseed',\n",
       " 'bladderweed',\n",
       " 'bladed',\n",
       " 'blakeberyed',\n",
       " 'blamed',\n",
       " 'blanked',\n",
       " 'blanketed',\n",
       " 'blanketweed',\n",
       " 'blasted',\n",
       " 'bleached',\n",
       " 'bleared',\n",
       " 'bleed',\n",
       " 'blended',\n",
       " 'blessed',\n",
       " 'blighted',\n",
       " 'blinded',\n",
       " 'blindfolded',\n",
       " 'blindweed',\n",
       " 'blinked',\n",
       " 'blinkered',\n",
       " 'blistered',\n",
       " 'blisterweed',\n",
       " 'blithehearted',\n",
       " 'bloated',\n",
       " 'blobbed',\n",
       " 'blocked',\n",
       " 'blockheaded',\n",
       " 'blooded',\n",
       " 'bloodied',\n",
       " 'bloodshed',\n",
       " 'bloodstained',\n",
       " 'bloodweed',\n",
       " 'blossomed',\n",
       " 'blotched',\n",
       " 'bloused',\n",
       " 'blowzed',\n",
       " 'bludgeoned',\n",
       " 'bluebelled',\n",
       " 'bluehearted',\n",
       " 'blueweed',\n",
       " 'blunderheaded',\n",
       " 'blunthearted',\n",
       " 'blurred',\n",
       " 'bobbed',\n",
       " 'bobsled',\n",
       " 'bobtailed',\n",
       " 'bodiced',\n",
       " 'bodied',\n",
       " 'boiled',\n",
       " 'boldhearted',\n",
       " 'bolectioned',\n",
       " 'boled',\n",
       " 'boleweed',\n",
       " 'bolled',\n",
       " 'bombed',\n",
       " 'bonded',\n",
       " 'boned',\n",
       " 'boneheaded',\n",
       " 'bonneted',\n",
       " 'booked',\n",
       " 'booted',\n",
       " 'bootied',\n",
       " 'boozed',\n",
       " 'bordered',\n",
       " 'bordured',\n",
       " 'bosomed',\n",
       " 'bossed',\n",
       " 'bosselated',\n",
       " 'botched',\n",
       " 'botherheaded',\n",
       " 'bothsided',\n",
       " 'bottled',\n",
       " 'bottomed',\n",
       " 'boughed',\n",
       " 'bounded',\n",
       " 'bountied',\n",
       " 'bowed',\n",
       " 'boweled',\n",
       " 'bowlegged',\n",
       " 'bowstringed',\n",
       " 'braced',\n",
       " 'braceleted',\n",
       " 'brackened',\n",
       " 'bracted',\n",
       " 'braided',\n",
       " 'brambled',\n",
       " 'branched',\n",
       " 'branded',\n",
       " 'brandied',\n",
       " 'brangled',\n",
       " 'bravehearted',\n",
       " 'brawned',\n",
       " 'brazenfaced',\n",
       " 'breasted',\n",
       " 'breastweed',\n",
       " 'breathed',\n",
       " 'brecciated',\n",
       " 'bred',\n",
       " 'breeched',\n",
       " 'breed',\n",
       " 'breviped',\n",
       " 'bridebed',\n",
       " 'brideweed',\n",
       " 'bridged',\n",
       " 'bridled',\n",
       " 'briered',\n",
       " 'brimmed',\n",
       " 'bristled',\n",
       " 'broadhearted',\n",
       " 'brocaded',\n",
       " 'brocked',\n",
       " 'brokenhearted',\n",
       " 'bromoiodized',\n",
       " 'bronzed',\n",
       " 'brooked',\n",
       " 'brookweed',\n",
       " 'broomweed',\n",
       " 'broozled',\n",
       " 'browed',\n",
       " 'brownweed',\n",
       " 'bruckled',\n",
       " 'brushed',\n",
       " 'buboed',\n",
       " 'bucked',\n",
       " 'buckled',\n",
       " 'buckskinned',\n",
       " 'buffed',\n",
       " 'bugled',\n",
       " 'bugleweed',\n",
       " 'bugseed',\n",
       " 'bugweed',\n",
       " 'bulbed',\n",
       " 'bulked',\n",
       " 'bulkheaded',\n",
       " 'bullated',\n",
       " 'bulldogged',\n",
       " 'bulleted',\n",
       " 'bulletheaded',\n",
       " 'bullheaded',\n",
       " 'bullweed',\n",
       " 'bummed',\n",
       " 'bundlerooted',\n",
       " 'bundweed',\n",
       " 'bunted',\n",
       " 'buried',\n",
       " 'burled',\n",
       " 'burned',\n",
       " 'burnoosed',\n",
       " 'burntweed',\n",
       " 'burred',\n",
       " 'burroweed',\n",
       " 'burseed',\n",
       " 'burweed',\n",
       " 'bushed',\n",
       " 'busied',\n",
       " 'busked',\n",
       " 'buskined',\n",
       " 'busted',\n",
       " 'bustled',\n",
       " 'busybodied',\n",
       " 'buttered',\n",
       " 'butterfingered',\n",
       " 'butterweed',\n",
       " 'butteryfingered',\n",
       " 'buttocked',\n",
       " 'buttoned',\n",
       " 'buttonweed',\n",
       " 'cabled',\n",
       " 'caboshed',\n",
       " 'caddiced',\n",
       " 'caddised',\n",
       " 'cadenced',\n",
       " 'cadweed',\n",
       " 'caftaned',\n",
       " 'caged',\n",
       " 'cairned',\n",
       " 'caissoned',\n",
       " 'calced',\n",
       " 'calcified',\n",
       " 'calcined',\n",
       " 'calculated',\n",
       " 'calibered',\n",
       " 'calicoed',\n",
       " 'caligated',\n",
       " 'calpacked',\n",
       " 'calved',\n",
       " 'calycled',\n",
       " 'calyculated',\n",
       " 'camailed',\n",
       " 'camerated',\n",
       " 'cammed',\n",
       " 'campanulated',\n",
       " 'campshed',\n",
       " 'camused',\n",
       " 'canaliculated',\n",
       " 'cancellated',\n",
       " 'cancered',\n",
       " 'cancerweed',\n",
       " 'candied',\n",
       " 'candlelighted',\n",
       " 'candlesticked',\n",
       " 'candyweed',\n",
       " 'canioned',\n",
       " 'cankered',\n",
       " 'cankerweed',\n",
       " 'canned',\n",
       " 'cannelated',\n",
       " 'cannelured',\n",
       " 'cannoned',\n",
       " 'cannulated',\n",
       " 'canted',\n",
       " 'cantilevered',\n",
       " 'cantoned',\n",
       " 'cantred',\n",
       " 'caped',\n",
       " 'capernoited',\n",
       " 'capeweed',\n",
       " 'capitaled',\n",
       " 'capitated',\n",
       " 'capped',\n",
       " 'capriped',\n",
       " 'capsulated',\n",
       " 'capuched',\n",
       " 'carapaced',\n",
       " 'carbolated',\n",
       " 'carboyed',\n",
       " 'carbuncled',\n",
       " 'carcaneted',\n",
       " 'carded',\n",
       " 'carinated',\n",
       " 'carkled',\n",
       " 'carnaged',\n",
       " 'carnationed',\n",
       " 'carpetweed',\n",
       " 'carried',\n",
       " 'carrotweed',\n",
       " 'carucated',\n",
       " 'carunculated',\n",
       " 'cased',\n",
       " 'casemated',\n",
       " 'casemented',\n",
       " 'caseweed',\n",
       " 'casqued',\n",
       " 'castellated',\n",
       " 'castled',\n",
       " 'castorized',\n",
       " 'catamited',\n",
       " 'cataracted',\n",
       " 'catarrhed',\n",
       " 'catchweed',\n",
       " 'catenated',\n",
       " 'caterpillared',\n",
       " 'catfaced',\n",
       " 'catfooted',\n",
       " 'cathedraled',\n",
       " 'caudated',\n",
       " 'caverned',\n",
       " 'cavitied',\n",
       " 'cayenned',\n",
       " 'cedared',\n",
       " 'ceilinged',\n",
       " 'celebrated',\n",
       " 'cellated',\n",
       " 'celled',\n",
       " 'cellulated',\n",
       " 'celluloided',\n",
       " 'centered',\n",
       " 'centriffed',\n",
       " 'centuried',\n",
       " 'cerated',\n",
       " 'cered',\n",
       " 'certified',\n",
       " 'chafeweed',\n",
       " 'chaffseed',\n",
       " 'chaffweed',\n",
       " 'chafted',\n",
       " 'chained',\n",
       " 'chaliced',\n",
       " 'chambered',\n",
       " 'chamberleted',\n",
       " 'chamberletted',\n",
       " 'chanceled',\n",
       " 'channeled',\n",
       " 'channelled',\n",
       " 'chaped',\n",
       " 'chapleted',\n",
       " 'chapournetted',\n",
       " 'chapped',\n",
       " 'charioted',\n",
       " 'charqued',\n",
       " 'chartered',\n",
       " 'chasmed',\n",
       " 'chasteweed',\n",
       " 'chasubled',\n",
       " 'checked',\n",
       " 'checkered',\n",
       " 'checkrowed',\n",
       " 'cheered',\n",
       " 'cheliped',\n",
       " 'cherried',\n",
       " 'chickenbreasted',\n",
       " 'chickenhearted',\n",
       " 'chickenweed',\n",
       " 'chickweed',\n",
       " 'chicqued',\n",
       " 'chiggerweed',\n",
       " 'chignoned',\n",
       " 'childbed',\n",
       " 'childed',\n",
       " 'chilled',\n",
       " 'chined',\n",
       " 'chinned',\n",
       " 'chipped',\n",
       " 'chiseled',\n",
       " 'chitinized',\n",
       " 'chokered',\n",
       " 'chokeweed',\n",
       " 'cholterheaded',\n",
       " 'chopped',\n",
       " 'choppered',\n",
       " 'chorded',\n",
       " 'chowderheaded',\n",
       " 'christened',\n",
       " 'chubbed',\n",
       " 'chuckleheaded',\n",
       " 'churchified',\n",
       " 'churled',\n",
       " 'ciliated',\n",
       " 'cingulated',\n",
       " 'cinnamoned',\n",
       " 'cinquefoiled',\n",
       " 'circled',\n",
       " 'circumscribed',\n",
       " 'circumstanced',\n",
       " 'cirrated',\n",
       " 'cirrhosed',\n",
       " 'cirriped',\n",
       " 'cisted',\n",
       " 'citied',\n",
       " 'citified',\n",
       " 'citrated',\n",
       " 'civilized',\n",
       " 'clammed',\n",
       " 'clammyweed',\n",
       " 'clanned',\n",
       " 'clapped',\n",
       " 'classed',\n",
       " 'classified',\n",
       " 'clavated',\n",
       " 'clavellated',\n",
       " 'clawed',\n",
       " 'claybrained',\n",
       " 'clayweed',\n",
       " 'cleaded',\n",
       " 'cleanhanded',\n",
       " 'cleanhearted',\n",
       " 'clearheaded',\n",
       " 'clearhearted',\n",
       " 'clearweed',\n",
       " 'cled',\n",
       " 'cleeked',\n",
       " 'clefted',\n",
       " 'clerestoried',\n",
       " 'cliented',\n",
       " 'cliffed',\n",
       " 'cliffweed',\n",
       " 'clipped',\n",
       " 'cloaked',\n",
       " 'clocked',\n",
       " 'clodpated',\n",
       " 'cloistered',\n",
       " 'closed',\n",
       " 'closefisted',\n",
       " 'closehanded',\n",
       " 'closehearted',\n",
       " 'closemouthed',\n",
       " 'clotweed',\n",
       " 'clouded',\n",
       " 'clouted',\n",
       " 'clovered',\n",
       " 'clubbed',\n",
       " 'clubfisted',\n",
       " 'clubfooted',\n",
       " 'clubweed',\n",
       " 'clustered',\n",
       " 'coaged',\n",
       " 'coaggregated',\n",
       " 'coated',\n",
       " 'coattailed',\n",
       " 'cobbed',\n",
       " 'cocashweed',\n",
       " 'cochleated',\n",
       " 'cockaded',\n",
       " 'cocked',\n",
       " 'cockeyed',\n",
       " 'cockled',\n",
       " 'cockneybred',\n",
       " 'cockscombed',\n",
       " 'cockweed',\n",
       " 'codheaded',\n",
       " 'coed',\n",
       " 'coelongated',\n",
       " 'coembedded',\n",
       " 'coequated',\n",
       " 'coexpanded',\n",
       " 'coffeeweed',\n",
       " 'cogged',\n",
       " 'coifed',\n",
       " 'coiled',\n",
       " 'coldhearted',\n",
       " 'coleseed',\n",
       " 'colicweed',\n",
       " 'collared',\n",
       " 'collected',\n",
       " 'collied',\n",
       " 'colloped',\n",
       " 'colonnaded',\n",
       " 'colored',\n",
       " 'columnated',\n",
       " 'columned',\n",
       " 'combed',\n",
       " 'combined',\n",
       " 'compacted',\n",
       " 'complected',\n",
       " 'complexioned',\n",
       " 'complicated',\n",
       " 'componed',\n",
       " 'componented',\n",
       " 'composed',\n",
       " 'compressed',\n",
       " 'comprised',\n",
       " 'compulsed',\n",
       " 'conamed',\n",
       " 'concamerated',\n",
       " 'concealed',\n",
       " 'conceded',\n",
       " 'conceited',\n",
       " 'concentrated',\n",
       " 'concerned',\n",
       " 'concerted',\n",
       " 'conched',\n",
       " 'conchyliated',\n",
       " 'condemned',\n",
       " 'condensed',\n",
       " 'conditioned',\n",
       " 'conduplicated',\n",
       " 'coned',\n",
       " 'confated',\n",
       " 'conferted',\n",
       " 'confined',\n",
       " 'confirmed',\n",
       " 'conflated',\n",
       " 'confounded',\n",
       " 'confused',\n",
       " 'congested',\n",
       " 'conjoined',\n",
       " 'conjugated',\n",
       " 'connected',\n",
       " 'conred',\n",
       " 'consecrated',\n",
       " 'considered',\n",
       " 'consolidated',\n",
       " 'constrained',\n",
       " 'constricted',\n",
       " 'consumpted',\n",
       " 'contagioned',\n",
       " 'contented',\n",
       " 'contextured',\n",
       " 'continued',\n",
       " 'contorted',\n",
       " 'contortioned',\n",
       " 'contracted',\n",
       " 'contractured',\n",
       " 'contusioned',\n",
       " 'converted',\n",
       " 'convexed',\n",
       " 'convinced',\n",
       " 'convoluted',\n",
       " 'coolheaded',\n",
       " 'coolweed',\n",
       " 'copied',\n",
       " 'copleased',\n",
       " 'copped',\n",
       " 'coppernosed',\n",
       " 'copperytailed',\n",
       " 'coppiced',\n",
       " 'coppled',\n",
       " 'copsewooded',\n",
       " 'copygraphed',\n",
       " 'coraled',\n",
       " 'corded',\n",
       " 'corduroyed',\n",
       " 'cored',\n",
       " 'coreflexed',\n",
       " 'corked',\n",
       " 'cornered',\n",
       " 'cornified',\n",
       " 'cornuated',\n",
       " 'cornuted',\n",
       " 'corollated',\n",
       " 'coronaled',\n",
       " 'coronated',\n",
       " 'coroneted',\n",
       " 'coronetted',\n",
       " 'corpusculated',\n",
       " 'corrected',\n",
       " 'correlated',\n",
       " 'corridored',\n",
       " ...]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('ed$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abjectly',\n",
       " 'adjuster',\n",
       " 'dejected',\n",
       " 'dejectly',\n",
       " 'injector',\n",
       " 'majestic',\n",
       " 'objectee',\n",
       " 'objector',\n",
       " 'rejecter',\n",
       " 'rejector',\n",
       " 'unjilted',\n",
       " 'unjolted',\n",
       " 'unjustly']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^..j..t..$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gold', 'golf', 'hold', 'hole']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
       " 'miiiiiinnnnnnnnnneeeeeeee',\n",
       " 'mine',\n",
       " 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))\n",
    "[w for w in chat_words if re.search('^m+i+n+e+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aaaaaaaaaaaaaaaaa',\n",
       " 'aaahhhh',\n",
       " 'ah',\n",
       " 'ahah',\n",
       " 'ahahah',\n",
       " 'ahh',\n",
       " 'ahhahahaha',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhhh',\n",
       " 'ahhhhhhhhhhhhhh',\n",
       " 'h',\n",
       " 'ha',\n",
       " 'haaa',\n",
       " 'hah',\n",
       " 'haha',\n",
       " 'hahaaa',\n",
       " 'hahah',\n",
       " 'hahaha',\n",
       " 'hahahaa',\n",
       " 'hahahah',\n",
       " 'hahahaha',\n",
       " 'hahahahaaa',\n",
       " 'hahahahahaha',\n",
       " 'hahahahahahaha',\n",
       " 'hahahahahahahahahahahahahahahaha',\n",
       " 'hahahhahah',\n",
       " 'hahhahahaha']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in chat_words if re.search('^[ha]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0085',\n",
       " '0.05',\n",
       " '0.1',\n",
       " '0.16',\n",
       " '0.2',\n",
       " '0.25',\n",
       " '0.28',\n",
       " '0.3',\n",
       " '0.4',\n",
       " '0.5',\n",
       " '0.50',\n",
       " '0.54',\n",
       " '0.56',\n",
       " '0.60',\n",
       " '0.7',\n",
       " '0.82',\n",
       " '0.84',\n",
       " '0.9',\n",
       " '0.95',\n",
       " '0.99',\n",
       " '1.01',\n",
       " '1.1',\n",
       " '1.125',\n",
       " '1.14',\n",
       " '1.1650',\n",
       " '1.17',\n",
       " '1.18',\n",
       " '1.19',\n",
       " '1.2',\n",
       " '1.20',\n",
       " '1.24',\n",
       " '1.25',\n",
       " '1.26',\n",
       " '1.28',\n",
       " '1.35',\n",
       " '1.39',\n",
       " '1.4',\n",
       " '1.457',\n",
       " '1.46',\n",
       " '1.49',\n",
       " '1.5',\n",
       " '1.50',\n",
       " '1.55',\n",
       " '1.56',\n",
       " '1.5755',\n",
       " '1.5805',\n",
       " '1.6',\n",
       " '1.61',\n",
       " '1.637',\n",
       " '1.64',\n",
       " '1.65',\n",
       " '1.7',\n",
       " '1.75',\n",
       " '1.76',\n",
       " '1.8',\n",
       " '1.82',\n",
       " '1.8415',\n",
       " '1.85',\n",
       " '1.8500',\n",
       " '1.9',\n",
       " '1.916',\n",
       " '1.92',\n",
       " '10.19',\n",
       " '10.2',\n",
       " '10.5',\n",
       " '107.03',\n",
       " '107.9',\n",
       " '109.73',\n",
       " '11.10',\n",
       " '11.5',\n",
       " '11.57',\n",
       " '11.6',\n",
       " '11.72',\n",
       " '11.95',\n",
       " '112.9',\n",
       " '113.2',\n",
       " '116.3',\n",
       " '116.4',\n",
       " '116.7',\n",
       " '116.9',\n",
       " '118.6',\n",
       " '12.09',\n",
       " '12.5',\n",
       " '12.52',\n",
       " '12.68',\n",
       " '12.7',\n",
       " '12.82',\n",
       " '12.97',\n",
       " '120.7',\n",
       " '1206.26',\n",
       " '121.6',\n",
       " '126.1',\n",
       " '126.15',\n",
       " '127.03',\n",
       " '129.91',\n",
       " '13.1',\n",
       " '13.15',\n",
       " '13.5',\n",
       " '13.50',\n",
       " '13.625',\n",
       " '13.65',\n",
       " '13.73',\n",
       " '13.8',\n",
       " '13.90',\n",
       " '130.6',\n",
       " '130.7',\n",
       " '131.01',\n",
       " '132.9',\n",
       " '133.7',\n",
       " '133.8',\n",
       " '14.00',\n",
       " '14.13',\n",
       " '14.26',\n",
       " '14.28',\n",
       " '14.43',\n",
       " '14.5',\n",
       " '14.53',\n",
       " '14.54',\n",
       " '14.6',\n",
       " '14.75',\n",
       " '14.99',\n",
       " '141.9',\n",
       " '142.84',\n",
       " '142.85',\n",
       " '143.08',\n",
       " '143.80',\n",
       " '143.93',\n",
       " '148.9',\n",
       " '149.9',\n",
       " '15.5',\n",
       " '150.00',\n",
       " '153.3',\n",
       " '154.2',\n",
       " '16.05',\n",
       " '16.09',\n",
       " '16.125',\n",
       " '16.2',\n",
       " '16.5',\n",
       " '16.68',\n",
       " '16.7',\n",
       " '16.9',\n",
       " '169.9',\n",
       " '17.3',\n",
       " '17.4',\n",
       " '17.5',\n",
       " '17.95',\n",
       " '1738.1',\n",
       " '176.1',\n",
       " '18.3',\n",
       " '18.6',\n",
       " '18.95',\n",
       " '185.9',\n",
       " '188.84',\n",
       " '19.3',\n",
       " '19.50',\n",
       " '19.6',\n",
       " '19.94',\n",
       " '19.95',\n",
       " '191.9',\n",
       " '2.07',\n",
       " '2.1',\n",
       " '2.15',\n",
       " '2.19',\n",
       " '2.2',\n",
       " '2.25',\n",
       " '2.29',\n",
       " '2.3',\n",
       " '2.30',\n",
       " '2.35',\n",
       " '2.375',\n",
       " '2.4',\n",
       " '2.42',\n",
       " '2.44',\n",
       " '2.46',\n",
       " '2.47',\n",
       " '2.5',\n",
       " '2.50',\n",
       " '2.6',\n",
       " '2.62',\n",
       " '2.65',\n",
       " '2.7',\n",
       " '2.75',\n",
       " '2.8',\n",
       " '2.80',\n",
       " '2.87',\n",
       " '2.875',\n",
       " '2.9',\n",
       " '2.95',\n",
       " '20.07',\n",
       " '20.5',\n",
       " '21.1',\n",
       " '21.9',\n",
       " '2141.7',\n",
       " '2160.1',\n",
       " '2163.2',\n",
       " '22.75',\n",
       " '220.45',\n",
       " '221.4',\n",
       " '225.6',\n",
       " '23.25',\n",
       " '23.4',\n",
       " '23.5',\n",
       " '23.72',\n",
       " '234.4',\n",
       " '236.74',\n",
       " '236.79',\n",
       " '24.95',\n",
       " '25.50',\n",
       " '25.6',\n",
       " '251.2',\n",
       " '26.2',\n",
       " '26.5',\n",
       " '26.8',\n",
       " '263.07',\n",
       " '2645.90',\n",
       " '2691.19',\n",
       " '27.1',\n",
       " '27.4',\n",
       " '273.5',\n",
       " '278.7',\n",
       " '28.25',\n",
       " '28.36',\n",
       " '28.4',\n",
       " '28.5',\n",
       " '28.53',\n",
       " '28.6',\n",
       " '29.3',\n",
       " '29.4',\n",
       " '29.9',\n",
       " '292.32',\n",
       " '3.01',\n",
       " '3.04',\n",
       " '3.1',\n",
       " '3.16',\n",
       " '3.18',\n",
       " '3.19',\n",
       " '3.2',\n",
       " '3.20',\n",
       " '3.23',\n",
       " '3.253',\n",
       " '3.28',\n",
       " '3.3',\n",
       " '3.35',\n",
       " '3.375',\n",
       " '3.4',\n",
       " '3.42',\n",
       " '3.43',\n",
       " '3.5',\n",
       " '3.55',\n",
       " '3.6',\n",
       " '3.61',\n",
       " '3.625',\n",
       " '3.7',\n",
       " '3.75',\n",
       " '3.8',\n",
       " '3.80',\n",
       " '3.9',\n",
       " '30.6',\n",
       " '30.9',\n",
       " '319.75',\n",
       " '32.8',\n",
       " '334.5',\n",
       " '34.625',\n",
       " '341.20',\n",
       " '3436.58',\n",
       " '35.2',\n",
       " '35.7',\n",
       " '352.7',\n",
       " '352.9',\n",
       " '35500.64',\n",
       " '35564.43',\n",
       " '36.9',\n",
       " '361.8',\n",
       " '3648.82',\n",
       " '37.3',\n",
       " '37.5',\n",
       " '372.14',\n",
       " '372.9',\n",
       " '374.19',\n",
       " '374.20',\n",
       " '377.60',\n",
       " '38.3',\n",
       " '38.375',\n",
       " '38.5',\n",
       " '38.875',\n",
       " '387.8',\n",
       " '4.1',\n",
       " '4.10',\n",
       " '4.2',\n",
       " '4.25',\n",
       " '4.3',\n",
       " '4.4',\n",
       " '4.5',\n",
       " '4.55',\n",
       " '4.6',\n",
       " '4.7',\n",
       " '4.75',\n",
       " '4.8',\n",
       " '4.875',\n",
       " '4.898',\n",
       " '4.9',\n",
       " '40.21',\n",
       " '41.60',\n",
       " '415.6',\n",
       " '415.8',\n",
       " '42.1',\n",
       " '42.5',\n",
       " '422.5',\n",
       " '43.875',\n",
       " '434.4',\n",
       " '436.01',\n",
       " '446.62',\n",
       " '449.04',\n",
       " '45.2',\n",
       " '45.3',\n",
       " '45.75',\n",
       " '456.64',\n",
       " '46.1',\n",
       " '47.1',\n",
       " '47.125',\n",
       " '47.5',\n",
       " '47.6',\n",
       " '49.9',\n",
       " '494.50',\n",
       " '497.34',\n",
       " '5.1',\n",
       " '5.2180',\n",
       " '5.276',\n",
       " '5.29',\n",
       " '5.3',\n",
       " '5.39',\n",
       " '5.4',\n",
       " '5.435',\n",
       " '5.5',\n",
       " '5.57',\n",
       " '5.6',\n",
       " '5.63',\n",
       " '5.7',\n",
       " '5.70',\n",
       " '5.8',\n",
       " '5.82',\n",
       " '5.9',\n",
       " '5.92',\n",
       " '50.1',\n",
       " '50.38',\n",
       " '50.45',\n",
       " '51.25',\n",
       " '51.6',\n",
       " '55.1',\n",
       " '566.54',\n",
       " '57.50',\n",
       " '57.6',\n",
       " '57.7',\n",
       " '58.64',\n",
       " '59.6',\n",
       " '59.9',\n",
       " '6.03',\n",
       " '6.1',\n",
       " '6.20',\n",
       " '6.21',\n",
       " '6.25',\n",
       " '6.4',\n",
       " '6.40',\n",
       " '6.44',\n",
       " '6.5',\n",
       " '6.50',\n",
       " '6.53',\n",
       " '6.6',\n",
       " '6.7',\n",
       " '6.70',\n",
       " '6.79',\n",
       " '6.84',\n",
       " '6.9',\n",
       " '60.36',\n",
       " '618.1',\n",
       " '62.1',\n",
       " '62.5',\n",
       " '62.625',\n",
       " '63.79',\n",
       " '630.9',\n",
       " '64.5',\n",
       " '66.5',\n",
       " '7.15',\n",
       " '7.2',\n",
       " '7.20',\n",
       " '7.272',\n",
       " '7.3',\n",
       " '7.4',\n",
       " '7.40',\n",
       " '7.422',\n",
       " '7.45',\n",
       " '7.458',\n",
       " '7.5',\n",
       " '7.50',\n",
       " '7.52',\n",
       " '7.55',\n",
       " '7.60',\n",
       " '7.62',\n",
       " '7.63',\n",
       " '7.65',\n",
       " '7.74',\n",
       " '7.78',\n",
       " '7.79',\n",
       " '7.8',\n",
       " '7.80',\n",
       " '7.84',\n",
       " '7.88',\n",
       " '7.90',\n",
       " '7.95',\n",
       " '70.2',\n",
       " '70.7',\n",
       " '705.6',\n",
       " '72.7',\n",
       " '734.9',\n",
       " '737.5',\n",
       " '77.56',\n",
       " '77.6',\n",
       " '77.70',\n",
       " '8.04',\n",
       " '8.06',\n",
       " '8.07',\n",
       " '8.1',\n",
       " '8.12',\n",
       " '8.14',\n",
       " '8.15',\n",
       " '8.19',\n",
       " '8.2',\n",
       " '8.22',\n",
       " '8.25',\n",
       " '8.30',\n",
       " '8.35',\n",
       " '8.45',\n",
       " '8.467',\n",
       " '8.47',\n",
       " '8.48',\n",
       " '8.5',\n",
       " '8.50',\n",
       " '8.53',\n",
       " '8.55',\n",
       " '8.56',\n",
       " '8.575',\n",
       " '8.60',\n",
       " '8.64',\n",
       " '8.65',\n",
       " '8.70',\n",
       " '8.75',\n",
       " '8.9',\n",
       " '80.50',\n",
       " '80.8',\n",
       " '81.8',\n",
       " '811.9',\n",
       " '83.4',\n",
       " '84.29',\n",
       " '84.9',\n",
       " '85.1',\n",
       " '85.7',\n",
       " '86.12',\n",
       " '87.5',\n",
       " '88.32',\n",
       " '89.7',\n",
       " '89.9',\n",
       " '9.3',\n",
       " '9.32',\n",
       " '9.37',\n",
       " '9.45',\n",
       " '9.5',\n",
       " '9.625',\n",
       " '9.75',\n",
       " '9.8',\n",
       " '9.82',\n",
       " '9.9',\n",
       " '92.9',\n",
       " '93.3',\n",
       " '93.9',\n",
       " '94.2',\n",
       " '94.8',\n",
       " '95.09',\n",
       " '96.4',\n",
       " '98.3',\n",
       " '99.1',\n",
       " '99.3']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "[w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C$', 'US$']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
    "['C$', 'US$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1614',\n",
       " '1637',\n",
       " '1787',\n",
       " '1901',\n",
       " '1903',\n",
       " '1917',\n",
       " '1925',\n",
       " '1929',\n",
       " '1933',\n",
       " '1934',\n",
       " '1948',\n",
       " '1953',\n",
       " '1955',\n",
       " '1956',\n",
       " '1961',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1979',\n",
       " '1980',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '2000',\n",
       " '2005',\n",
       " '2009',\n",
       " '2017',\n",
       " '2019',\n",
       " '2029',\n",
       " '3057',\n",
       " '8300']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [w for w in wsj if re.search('^[0-9]{4}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-day',\n",
       " '10-lap',\n",
       " '10-year',\n",
       " '100-share',\n",
       " '12-point',\n",
       " '12-year',\n",
       " '14-hour',\n",
       " '15-day',\n",
       " '150-point',\n",
       " '190-point',\n",
       " '20-point',\n",
       " '20-stock',\n",
       " '21-month',\n",
       " '237-seat',\n",
       " '240-page',\n",
       " '27-year',\n",
       " '30-day',\n",
       " '30-point',\n",
       " '30-share',\n",
       " '30-year',\n",
       " '300-day',\n",
       " '36-day',\n",
       " '36-store',\n",
       " '42-year',\n",
       " '50-state',\n",
       " '500-stock',\n",
       " '52-week',\n",
       " '69-point',\n",
       " '84-month',\n",
       " '87-store',\n",
       " '90-day']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black-and-white',\n",
       " 'bread-and-butter',\n",
       " 'father-in-law',\n",
       " 'machine-gun-toting',\n",
       " 'savings-and-loan']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['62%-owned',\n",
       " 'Absorbed',\n",
       " 'According',\n",
       " 'Adopting',\n",
       " 'Advanced',\n",
       " 'Advancing',\n",
       " 'Alfred',\n",
       " 'Allied',\n",
       " 'Annualized',\n",
       " 'Anything',\n",
       " 'Arbitrage-related',\n",
       " 'Arbitraging',\n",
       " 'Asked',\n",
       " 'Assuming',\n",
       " 'Atlanta-based',\n",
       " 'Baking',\n",
       " 'Banking',\n",
       " 'Beginning',\n",
       " 'Beijing',\n",
       " 'Being',\n",
       " 'Bermuda-based',\n",
       " 'Betting',\n",
       " 'Boeing',\n",
       " 'Broadcasting',\n",
       " 'Bucking',\n",
       " 'Buying',\n",
       " 'Calif.-based',\n",
       " 'Change-ringing',\n",
       " 'Citing',\n",
       " 'Concerned',\n",
       " 'Confronted',\n",
       " 'Conn.based',\n",
       " 'Consolidated',\n",
       " 'Continued',\n",
       " 'Continuing',\n",
       " 'Declining',\n",
       " 'Defending',\n",
       " 'Depending',\n",
       " 'Designated',\n",
       " 'Determining',\n",
       " 'Developed',\n",
       " 'Died',\n",
       " 'During',\n",
       " 'Encouraged',\n",
       " 'Encouraging',\n",
       " 'English-speaking',\n",
       " 'Estimated',\n",
       " 'Everything',\n",
       " 'Excluding',\n",
       " 'Exxon-owned',\n",
       " 'Faulding',\n",
       " 'Fed',\n",
       " 'Feeding',\n",
       " 'Filling',\n",
       " 'Filmed',\n",
       " 'Financing',\n",
       " 'Following',\n",
       " 'Founded',\n",
       " 'Fracturing',\n",
       " 'Francisco-based',\n",
       " 'Fred',\n",
       " 'Funded',\n",
       " 'Funding',\n",
       " 'Generalized',\n",
       " 'Germany-based',\n",
       " 'Getting',\n",
       " 'Guaranteed',\n",
       " 'Having',\n",
       " 'Heating',\n",
       " 'Heightened',\n",
       " 'Holding',\n",
       " 'Housing',\n",
       " 'Illuminating',\n",
       " 'Indeed',\n",
       " 'Indexing',\n",
       " 'Irving',\n",
       " 'Jersey-based',\n",
       " 'Judging',\n",
       " 'Knowing',\n",
       " 'Learning',\n",
       " 'Legislating',\n",
       " 'Leming',\n",
       " 'Limited',\n",
       " 'London-based',\n",
       " 'Manfred',\n",
       " 'Manufacturing',\n",
       " 'Melamed',\n",
       " 'Miami-based',\n",
       " 'Mich.-based',\n",
       " 'Mining',\n",
       " 'Minneapolis-based',\n",
       " 'Mo.-based',\n",
       " 'Mortgage-Backed',\n",
       " 'Moving',\n",
       " 'Muzzling',\n",
       " 'N.J.-based',\n",
       " 'NBC-owned',\n",
       " 'NIH-appointed',\n",
       " 'Named',\n",
       " 'No-Smoking',\n",
       " 'Observing',\n",
       " 'Offering',\n",
       " 'Ohio-based',\n",
       " 'Orleans-based',\n",
       " 'Packaging',\n",
       " 'Performing',\n",
       " 'Philadelphia-based',\n",
       " 'Posted',\n",
       " 'Provided',\n",
       " 'Publishing',\n",
       " 'Purchasing',\n",
       " 'Rated',\n",
       " 'Reached',\n",
       " 'Red',\n",
       " 'Red-blooded',\n",
       " 'Reducing',\n",
       " 'Reed',\n",
       " 'Regarded',\n",
       " 'Rekindled',\n",
       " 'Related',\n",
       " 'Ringing',\n",
       " 'Rolling',\n",
       " 'Sacramento-based',\n",
       " 'Scoring',\n",
       " 'Seattle-based',\n",
       " 'Seed',\n",
       " 'Skilled',\n",
       " 'Smelting',\n",
       " 'Something',\n",
       " 'Spending',\n",
       " 'Standardized',\n",
       " 'Standing',\n",
       " 'Starting',\n",
       " 'Sterling',\n",
       " 'Taking',\n",
       " 'Texas-based',\n",
       " 'Toronto-based',\n",
       " 'Traded',\n",
       " 'Trading',\n",
       " 'Troubled',\n",
       " 'U.N.-supervised',\n",
       " 'U.S.-backed',\n",
       " 'United',\n",
       " 'Used',\n",
       " 'Varying',\n",
       " 'Washington-based',\n",
       " 'Whiting',\n",
       " 'Wilfred',\n",
       " 'Winning',\n",
       " 'Xiaoping',\n",
       " 'York-based',\n",
       " 'Zayed',\n",
       " 'abandoned',\n",
       " 'abating',\n",
       " 'abolishing',\n",
       " 'abortion-related',\n",
       " 'abounding',\n",
       " 'abridging',\n",
       " 'absorbed',\n",
       " 'acceded',\n",
       " 'accelerated',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'according',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accrued',\n",
       " 'accumulated',\n",
       " 'accused',\n",
       " 'accusing',\n",
       " 'achieved',\n",
       " 'achieving',\n",
       " 'acknowledging',\n",
       " 'acquired',\n",
       " 'acquiring',\n",
       " 'acquisition-minded',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addressing',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'adopted',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advertised',\n",
       " 'advertising',\n",
       " 'advised',\n",
       " 'advocated',\n",
       " 'advocating',\n",
       " 'affecting',\n",
       " 'afflicted',\n",
       " 'aggravated',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'ailing',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aired',\n",
       " 'airline-related',\n",
       " 'alarmed',\n",
       " 'alienated',\n",
       " 'alleged',\n",
       " 'alleging',\n",
       " 'allocated',\n",
       " 'allowed',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'amended',\n",
       " 'amending',\n",
       " 'amounted',\n",
       " 'amusing',\n",
       " 'angered',\n",
       " 'announced',\n",
       " 'annoyed',\n",
       " 'annualized',\n",
       " 'answered',\n",
       " 'anti-dumping',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anything',\n",
       " 'apologizing',\n",
       " 'appealing',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'applied',\n",
       " 'appointed',\n",
       " 'approached',\n",
       " 'appropriated',\n",
       " 'approved',\n",
       " 'arched',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'arising',\n",
       " 'armed',\n",
       " 'arranged',\n",
       " 'arrested',\n",
       " 'arrived',\n",
       " 'asbestos-related',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'assassinated',\n",
       " 'assembled',\n",
       " 'asserted',\n",
       " 'asserting',\n",
       " 'assessed',\n",
       " 'assigned',\n",
       " 'assisted',\n",
       " 'associated',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assured',\n",
       " 'attached',\n",
       " 'attacking',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attracted',\n",
       " 'attracting',\n",
       " 'attributed',\n",
       " 'auctioned',\n",
       " 'authorized',\n",
       " 'authorizing',\n",
       " 'automated',\n",
       " 'automotive-lighting',\n",
       " 'averaged',\n",
       " 'averted',\n",
       " 'avoiding',\n",
       " 'awarded',\n",
       " 'awarding',\n",
       " 'backed',\n",
       " 'backing',\n",
       " 'balanced',\n",
       " 'bald-faced',\n",
       " 'balkanized',\n",
       " 'balked',\n",
       " 'balloting',\n",
       " 'bank-backed',\n",
       " 'banking',\n",
       " 'banned',\n",
       " 'banning',\n",
       " 'barking',\n",
       " 'barred',\n",
       " 'based',\n",
       " 'battered',\n",
       " 'battery-operated',\n",
       " 'batting',\n",
       " 'bearing',\n",
       " 'becoming',\n",
       " 'bedding',\n",
       " 'befuddled',\n",
       " 'beginning',\n",
       " 'behaving',\n",
       " 'beheading',\n",
       " 'being',\n",
       " 'beleaguered',\n",
       " 'believed',\n",
       " 'bell-ringing',\n",
       " 'belonging',\n",
       " 'benefited',\n",
       " 'best-selling',\n",
       " 'betting',\n",
       " 'bickering',\n",
       " 'bidding',\n",
       " 'billed',\n",
       " 'billing',\n",
       " 'blamed',\n",
       " 'bled',\n",
       " 'blessing',\n",
       " 'blighted',\n",
       " 'blocked',\n",
       " 'blurred',\n",
       " 'boarding',\n",
       " 'bolstered',\n",
       " 'bombarding',\n",
       " 'booked',\n",
       " 'booming',\n",
       " 'boosted',\n",
       " 'boosting',\n",
       " 'borrowed',\n",
       " 'borrowing',\n",
       " 'botched',\n",
       " 'bothered',\n",
       " 'bounced',\n",
       " 'bowed',\n",
       " 'breaking',\n",
       " 'breathed',\n",
       " 'breathtaking',\n",
       " 'breed',\n",
       " 'bribed',\n",
       " 'bribing',\n",
       " 'briefing',\n",
       " 'brightened',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'broad-based',\n",
       " 'broadcasting',\n",
       " 'broadened',\n",
       " 'brokering',\n",
       " 'brushed',\n",
       " 'budding',\n",
       " 'building',\n",
       " 'bundling',\n",
       " 'buoyed',\n",
       " 'burned',\n",
       " 'buying',\n",
       " 'calculated',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'campaigning',\n",
       " 'cancer-causing',\n",
       " 'capitalized',\n",
       " 'capped',\n",
       " 'captivating',\n",
       " 'cared',\n",
       " 'carried',\n",
       " 'carrying',\n",
       " 'cascading',\n",
       " 'casting',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cautioned',\n",
       " 'ceiling',\n",
       " 'centralized',\n",
       " 'certified',\n",
       " 'chaired',\n",
       " 'challenging',\n",
       " 'championing',\n",
       " 'change-ringing',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'characterized',\n",
       " 'characterizing',\n",
       " 'charged',\n",
       " 'charging',\n",
       " 'chastised',\n",
       " 'cheating',\n",
       " 'checking',\n",
       " 'cheerleading',\n",
       " 'chilled',\n",
       " 'choosing',\n",
       " 'chopped',\n",
       " 'circulated',\n",
       " 'cited',\n",
       " 'citing',\n",
       " 'citizen-sparked',\n",
       " 'city-owned',\n",
       " 'claimed',\n",
       " 'claiming',\n",
       " 'clamped',\n",
       " 'clarified',\n",
       " 'clashed',\n",
       " 'classed',\n",
       " 'classified',\n",
       " 'cleaned',\n",
       " 'cleaner-burning',\n",
       " 'cleared',\n",
       " 'clearing',\n",
       " 'clicked',\n",
       " 'climbed',\n",
       " 'climbing',\n",
       " 'clipped',\n",
       " 'clobbered',\n",
       " 'closed',\n",
       " 'closing',\n",
       " 'clothing',\n",
       " 'clouding',\n",
       " 'cluttered',\n",
       " 'co-founded',\n",
       " 'coaching',\n",
       " 'coal-fired',\n",
       " 'coated',\n",
       " 'codified',\n",
       " 'collaborated',\n",
       " 'collapsed',\n",
       " 'collected',\n",
       " 'collecting',\n",
       " 'collective-bargaining',\n",
       " 'colored',\n",
       " 'combined',\n",
       " 'coming',\n",
       " 'commanded',\n",
       " 'commenting',\n",
       " 'committed',\n",
       " 'committing',\n",
       " 'compared',\n",
       " 'compelling',\n",
       " 'competed',\n",
       " 'competing',\n",
       " 'compiled',\n",
       " 'complained',\n",
       " 'complaining',\n",
       " 'completed',\n",
       " 'completing',\n",
       " 'complicated',\n",
       " 'composed',\n",
       " 'composting',\n",
       " 'compressed',\n",
       " 'computer-aided',\n",
       " 'computer-assisted',\n",
       " 'computer-generated',\n",
       " 'computerized',\n",
       " 'computing',\n",
       " 'conceding',\n",
       " 'concentrated',\n",
       " 'concentrating',\n",
       " 'concerned',\n",
       " 'concluded',\n",
       " 'condemned',\n",
       " 'condemning',\n",
       " 'conducted',\n",
       " 'conducting',\n",
       " 'confined',\n",
       " 'confirmed',\n",
       " 'confused',\n",
       " 'connected',\n",
       " 'consented',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consisting',\n",
       " 'construed',\n",
       " 'consulting',\n",
       " 'contacted',\n",
       " 'contained',\n",
       " 'containing',\n",
       " 'contesting',\n",
       " 'continued',\n",
       " 'continuing',\n",
       " 'contracted',\n",
       " 'contributed',\n",
       " 'contributing',\n",
       " 'controlled',\n",
       " 'controlling',\n",
       " 'converted',\n",
       " 'converting',\n",
       " 'convicted',\n",
       " 'convinced',\n",
       " 'cooled',\n",
       " 'cooperating',\n",
       " 'copied',\n",
       " 'copying',\n",
       " 'corn-buying',\n",
       " 'corrected',\n",
       " 'correcting',\n",
       " 'cost-cutting',\n",
       " 'cost-sharing',\n",
       " 'counseling',\n",
       " 'counting',\n",
       " 'coupled',\n",
       " 'court-ordered',\n",
       " 'covered',\n",
       " 'covering',\n",
       " 'cranked',\n",
       " 'crashing',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'credit-rating',\n",
       " 'crippled',\n",
       " 'criticized',\n",
       " 'crossed',\n",
       " 'crossing',\n",
       " 'crowded',\n",
       " 'cruising',\n",
       " 'crushed',\n",
       " 'crying',\n",
       " 'cultivated',\n",
       " 'curbed',\n",
       " 'curbing',\n",
       " 'curled',\n",
       " 'current-carrying',\n",
       " 'curtailed',\n",
       " 'cushioned',\n",
       " 'customized',\n",
       " 'cutting',\n",
       " 'damaged',\n",
       " 'damaging',\n",
       " 'dancing',\n",
       " 'darned',\n",
       " 'dashed',\n",
       " 'dating',\n",
       " 'dead-eyed',\n",
       " 'dealing',\n",
       " 'decided',\n",
       " 'declared',\n",
       " 'declaring',\n",
       " 'declined',\n",
       " 'declining',\n",
       " 'decorated',\n",
       " 'decried',\n",
       " 'deducting',\n",
       " 'deemed',\n",
       " 'defeated',\n",
       " 'defended',\n",
       " 'defined',\n",
       " 'defying',\n",
       " 'delayed',\n",
       " 'deliberating',\n",
       " 'delisted',\n",
       " 'delivered',\n",
       " 'delivering',\n",
       " 'demanding',\n",
       " 'demonstrating',\n",
       " 'denied',\n",
       " 'denouncing',\n",
       " 'denying',\n",
       " 'depended',\n",
       " 'depending',\n",
       " 'depleted',\n",
       " 'depressed',\n",
       " 'deprived',\n",
       " 'derived',\n",
       " 'descending',\n",
       " 'described',\n",
       " 'deserving',\n",
       " 'designated',\n",
       " 'designed',\n",
       " 'designing',\n",
       " 'desired',\n",
       " 'despised',\n",
       " 'detailed',\n",
       " 'deteriorated',\n",
       " 'deteriorating',\n",
       " 'determined',\n",
       " 'deterring',\n",
       " 'devastating',\n",
       " 'developed',\n",
       " 'developing',\n",
       " 'devised',\n",
       " 'devoted',\n",
       " 'devouring',\n",
       " 'diagnosed',\n",
       " 'died',\n",
       " 'diluted',\n",
       " 'diming',\n",
       " 'diminished',\n",
       " 'directed',\n",
       " 'directing',\n",
       " 'disaffected',\n",
       " 'disagreed',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disapproved',\n",
       " 'discarded',\n",
       " 'disciplined',\n",
       " 'disclosed',\n",
       " 'disclosing',\n",
       " 'discontinued',\n",
       " 'discontinuing',\n",
       " 'discouraging',\n",
       " 'discovered',\n",
       " 'discussed',\n",
       " 'discussing',\n",
       " 'disembodied',\n",
       " 'dismayed',\n",
       " 'dismissed',\n",
       " 'disposed',\n",
       " 'disputed',\n",
       " 'disseminating',\n",
       " 'distinguished',\n",
       " 'distorted',\n",
       " 'distributed',\n",
       " 'disturbing',\n",
       " 'diversified',\n",
       " 'diversifying',\n",
       " 'divided',\n",
       " 'dividing',\n",
       " 'documented',\n",
       " 'doing',\n",
       " 'doling',\n",
       " 'dollar-denominated',\n",
       " 'dominated',\n",
       " 'dominating',\n",
       " 'doubled',\n",
       " 'doubted',\n",
       " 'downgraded',\n",
       " 'downgrading',\n",
       " 'drafted',\n",
       " 'drawing',\n",
       " 'dreamed',\n",
       " 'dressed',\n",
       " 'drifted',\n",
       " 'drinking',\n",
       " 'driving',\n",
       " 'drooled',\n",
       " 'dropped',\n",
       " 'dubbed',\n",
       " 'duckling',\n",
       " 'dumbfounded',\n",
       " 'dumped',\n",
       " 'during',\n",
       " 'dwindling',\n",
       " 'earned',\n",
       " 'earning',\n",
       " 'eased',\n",
       " 'easing',\n",
       " 'eating',\n",
       " 'echoed',\n",
       " 'edged',\n",
       " 'editing',\n",
       " 'educated',\n",
       " 'elected',\n",
       " 'eliminated',\n",
       " 'eliminating',\n",
       " 'embarrassing',\n",
       " 'embroiled',\n",
       " 'emerged',\n",
       " 'emerging',\n",
       " 'emphasized',\n",
       " 'employed',\n",
       " 'empowered',\n",
       " 'enabled',\n",
       " 'enabling',\n",
       " 'enacted',\n",
       " 'encircling',\n",
       " 'enclosed',\n",
       " 'encouraging',\n",
       " 'encroaching',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'endorsed',\n",
       " 'engaged',\n",
       " 'engaging',\n",
       " 'engineered',\n",
       " 'engineering',\n",
       " 'enhanced',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enlarged',\n",
       " 'enraged',\n",
       " 'ensnarled',\n",
       " 'entangled',\n",
       " 'entered',\n",
       " 'entering',\n",
       " 'entertaining',\n",
       " 'enticed',\n",
       " 'entitled',\n",
       " 'entrenched',\n",
       " 'entrusted',\n",
       " 'equaling',\n",
       " 'equipped',\n",
       " 'escalated',\n",
       " 'escaped',\n",
       " 'established',\n",
       " 'establishing',\n",
       " 'estimated',\n",
       " 'evaluated',\n",
       " 'evaluating',\n",
       " 'evaporated',\n",
       " 'evening',\n",
       " 'everything',\n",
       " 'evoking',\n",
       " 'evolved',\n",
       " 'exacerbated',\n",
       " 'examined',\n",
       " 'exceed',\n",
       " 'exceeded',\n",
       " 'exceeding',\n",
       " 'exchanging',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'executed',\n",
       " 'executing',\n",
       " 'exercised',\n",
       " 'exerting',\n",
       " 'exhausted',\n",
       " 'exhibited',\n",
       " 'existed',\n",
       " 'existing',\n",
       " 'expanded',\n",
       " 'expanding',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expedited',\n",
       " 'expelled',\n",
       " 'experienced',\n",
       " 'experiencing',\n",
       " 'expired',\n",
       " 'explained',\n",
       " 'explaining',\n",
       " 'exploded',\n",
       " 'export-oriented',\n",
       " 'exposed',\n",
       " 'expressed',\n",
       " 'expressing',\n",
       " 'expunged',\n",
       " 'extended',\n",
       " 'extending',\n",
       " 'exuded',\n",
       " 'eyeing',\n",
       " 'fabled',\n",
       " 'faced',\n",
       " 'facing',\n",
       " 'factoring',\n",
       " 'faded',\n",
       " 'failed',\n",
       " 'failing',\n",
       " 'fainting',\n",
       " 'falling',\n",
       " 'faltered',\n",
       " 'famed',\n",
       " 'family-planning',\n",
       " 'fared',\n",
       " 'fashioned',\n",
       " 'fast-growing',\n",
       " 'fastest-growing',\n",
       " 'fattened',\n",
       " 'favored',\n",
       " 'fawning',\n",
       " 'feared',\n",
       " 'featured',\n",
       " 'featuring',\n",
       " 'fed',\n",
       " 'feed',\n",
       " 'feeling',\n",
       " 'fetching',\n",
       " 'fielded',\n",
       " 'fighting',\n",
       " 'filed',\n",
       " 'filing',\n",
       " 'filled',\n",
       " 'filling',\n",
       " 'finalized',\n",
       " 'financed',\n",
       " 'financing',\n",
       " 'finding',\n",
       " 'fined',\n",
       " 'finished',\n",
       " 'fired',\n",
       " 'firmed',\n",
       " 'fixed',\n",
       " 'fizzled',\n",
       " 'fled',\n",
       " 'fledgling',\n",
       " 'fleeting',\n",
       " 'flirted',\n",
       " 'floated',\n",
       " 'flooded',\n",
       " 'focused',\n",
       " 'focusing',\n",
       " 'folded',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'forced',\n",
       " 'forcing',\n",
       " 'forecasting',\n",
       " 'foreign-led',\n",
       " 'formed',\n",
       " 'forthcoming',\n",
       " 'founded',\n",
       " 'foundering',\n",
       " 'fretted',\n",
       " 'frightened',\n",
       " 'frustrating',\n",
       " 'fueled',\n",
       " 'fueling',\n",
       " 'full-fledged',\n",
       " 'fuming',\n",
       " 'functioning',\n",
       " 'funded',\n",
       " 'funding',\n",
       " 'fundraising',\n",
       " 'futures-related',\n",
       " 'gained',\n",
       " 'gaining',\n",
       " 'galling',\n",
       " 'galvanized',\n",
       " 'gambling',\n",
       " 'gauging',\n",
       " 'generated',\n",
       " 'getting',\n",
       " 'giving',\n",
       " 'going',\n",
       " 'good-hearted',\n",
       " 'good-natured',\n",
       " 'gored',\n",
       " 'government-certified',\n",
       " 'government-funded',\n",
       " 'government-owned',\n",
       " 'graduated',\n",
       " 'granted',\n",
       " 'granting',\n",
       " 'greed',\n",
       " 'gripping',\n",
       " 'growing',\n",
       " 'guaranteed',\n",
       " 'guarding',\n",
       " 'guided',\n",
       " 'gut-wrenching',\n",
       " 'hailed',\n",
       " 'hailing',\n",
       " 'halted',\n",
       " 'hampered',\n",
       " 'handed',\n",
       " 'handled',\n",
       " 'handling',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'hard-charging',\n",
       " 'hard-drinking',\n",
       " 'hard-hitting',\n",
       " 'harmed',\n",
       " 'harped',\n",
       " 'harvested',\n",
       " 'hauled',\n",
       " 'hauling',\n",
       " 'having',\n",
       " 'headed',\n",
       " 'heading',\n",
       " 'headlined',\n",
       " 'healing',\n",
       " 'hearing',\n",
       " 'heated',\n",
       " 'heating',\n",
       " 'hedging',\n",
       " 'heightened',\n",
       " 'helped',\n",
       " 'helping',\n",
       " 'high-flying',\n",
       " 'high-minded',\n",
       " 'high-polluting',\n",
       " 'high-priced',\n",
       " 'high-rolling',\n",
       " 'high-speed',\n",
       " 'higher-salaried',\n",
       " 'highest-pitched',\n",
       " 'hired',\n",
       " 'hitting',\n",
       " 'holding',\n",
       " 'hoped',\n",
       " 'hosted',\n",
       " 'housing',\n",
       " 'hugging',\n",
       " 'hundred',\n",
       " 'hunted',\n",
       " 'hurting',\n",
       " 'identified',\n",
       " 'ignored',\n",
       " 'ignoring',\n",
       " 'impaired',\n",
       " 'impeding',\n",
       " 'impending',\n",
       " 'implemented',\n",
       " 'implied',\n",
       " 'imported',\n",
       " 'imposed',\n",
       " 'imposing',\n",
       " 'impressed',\n",
       " 'improved',\n",
       " 'improving',\n",
       " 'incentive-backed',\n",
       " 'inched',\n",
       " 'inching',\n",
       " 'included',\n",
       " 'including',\n",
       " 'incorporated',\n",
       " 'increased',\n",
       " 'increasing',\n",
       " 'incurred',\n",
       " 'indeed',\n",
       " 'index-related',\n",
       " 'indicated',\n",
       " 'indicating',\n",
       " 'indulging',\n",
       " 'industrialized',\n",
       " 'industry-supported',\n",
       " 'inflated',\n",
       " 'influenced',\n",
       " 'influencing',\n",
       " 'infringed',\n",
       " 'inherited',\n",
       " 'initialing',\n",
       " 'initiated',\n",
       " 'initiating',\n",
       " 'injecting',\n",
       " 'injuring',\n",
       " 'inkling',\n",
       " 'inquiring',\n",
       " 'inserted',\n",
       " 'insider-trading',\n",
       " 'insinuating',\n",
       " 'insisted',\n",
       " 'inspired',\n",
       " 'installed',\n",
       " 'installing',\n",
       " 'instituted',\n",
       " 'instructed',\n",
       " 'insured',\n",
       " 'integrated',\n",
       " 'intended',\n",
       " 'intentioned',\n",
       " 'interest-bearing',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'interrogated',\n",
       " 'interviewed',\n",
       " 'intriguing',\n",
       " 'introduced',\n",
       " 'introducing',\n",
       " 'invented',\n",
       " 'inverted',\n",
       " 'invested',\n",
       " 'investigating',\n",
       " 'investing',\n",
       " 'inviting',\n",
       " 'involved',\n",
       " 'involving',\n",
       " 'issued',\n",
       " 'issuing',\n",
       " 'jeopardizing',\n",
       " 'joined',\n",
       " 'joining',\n",
       " 'judged',\n",
       " 'jumped',\n",
       " 'jumping',\n",
       " 'justified',\n",
       " 'justifying',\n",
       " 'keeping',\n",
       " 'kicked',\n",
       " 'kidnapping',\n",
       " 'killed',\n",
       " 'killing',\n",
       " 'knitted',\n",
       " 'knocked',\n",
       " 'labeled',\n",
       " 'labeling',\n",
       " 'labor-backed',\n",
       " 'lacked',\n",
       " 'lagging',\n",
       " 'land-idling',\n",
       " 'landing',\n",
       " 'lasted',\n",
       " 'lasting',\n",
       " 'lauded',\n",
       " 'laughing',\n",
       " 'launched',\n",
       " 'lawmaking',\n",
       " 'laying',\n",
       " 'leading',\n",
       " 'learned',\n",
       " 'learning',\n",
       " 'leasing',\n",
       " 'leaving',\n",
       " 'led',\n",
       " 'lending',\n",
       " 'lengthened',\n",
       " 'lessening',\n",
       " 'letter-writing',\n",
       " 'letting',\n",
       " 'leveling',\n",
       " 'leveraged',\n",
       " 'leveraging',\n",
       " 'licensed',\n",
       " 'licensing',\n",
       " 'lifted',\n",
       " ...]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('(ed|ing)$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'o',\n",
       " 'i',\n",
       " 'o',\n",
       " 'u']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall(r'[aeiou]', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(r'[aeiou]', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('io', 549),\n",
       " ('ea', 476),\n",
       " ('ie', 331),\n",
       " ('ou', 329),\n",
       " ('ai', 261),\n",
       " ('ia', 253),\n",
       " ('ee', 217),\n",
       " ('oo', 174),\n",
       " ('ua', 109),\n",
       " ('au', 106),\n",
       " ('ue', 105),\n",
       " ('ui', 95)]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "fd = nltk.FreqDist(vs for word in wsj\n",
    "for vs in re.findall(r'[aeiou]{2,}', word))\n",
    "fd.most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
      "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
      "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\n",
      "rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\n",
      "and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and\n"
     ]
    }
   ],
   "source": [
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'\n",
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "\n",
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "print(nltk.tokenwrap(compress(w) for w in english_udhr[:75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')\n",
    "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cfd = nltk.ConditionalFreqDist(cvs)\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaapo',\n",
       " 'kaapopato',\n",
       " 'kaipori',\n",
       " 'kaiporipie',\n",
       " 'kaiporivira',\n",
       " 'kapo',\n",
       " 'kapoa',\n",
       " 'kapokao',\n",
       " 'kapokapo',\n",
       " 'kapokapo',\n",
       " 'kapokapoa',\n",
       " 'kapokapoa',\n",
       " 'kapokapora',\n",
       " 'kapokapora',\n",
       " 'kapokaporo',\n",
       " 'kapokaporo',\n",
       " 'kapokari',\n",
       " 'kapokarito',\n",
       " 'kapokoa',\n",
       " 'kapoo',\n",
       " 'kapooto',\n",
       " 'kapoovira',\n",
       " 'kapopaa',\n",
       " 'kaporo',\n",
       " 'kaporo',\n",
       " 'kaporopa',\n",
       " 'kaporoto',\n",
       " 'kapoto',\n",
       " 'karokaropo',\n",
       " 'karopo',\n",
       " 'kepo',\n",
       " 'kepoi',\n",
       " 'keposi',\n",
       " 'kepoto']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_word_pairs = [(cv, w) for w in rotokas_words\n",
    "for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cv_index = nltk.Index(cv_word_pairs)\n",
    "cv_index['su']\n",
    "cv_index['po']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    for suffix in ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ing']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')\n",
    "['ing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processing']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'es')]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', '')]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$', 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'women',\n",
       " 'ly',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'i',\n",
       " 'no',\n",
       " 'basi',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'execut',\n",
       " 'power',\n",
       " 'deriv',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem(word):\n",
    "    regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "    stem, suffix = re.findall(regexp, word)[0]\n",
    "    return stem\n",
    "\n",
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = word_tokenize(raw)\n",
    "[stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "brave; brave; brave\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg, nps_chat\n",
    "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))\n",
    "moby.findall(r\"<a> (<.*>) <man>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rule bro; telling you bro; u twizted bro\n",
      "lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la\n",
      "la la; lovely lol lol love; lol lol lol.; la la la; la la la\n"
     ]
    }
   ],
   "source": [
    "chat = nltk.Text(nps_chat.words())\n",
    "chat.findall(r\"<.*> <.*> <bro>\") \n",
    "chat.findall(r\"<l.*>{3,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "hobbies_learned = nltk.Text(brown.words(categories=['hobbies', 'learned']))\n",
    "hobbies_learned.findall(r\"<\\w*> <and> <other> <\\w*s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = word_tokenize(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['denni',\n",
       " ':',\n",
       " 'listen',\n",
       " ',',\n",
       " 'strang',\n",
       " 'women',\n",
       " 'lie',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basi',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'suprem',\n",
       " 'execut',\n",
       " 'power',\n",
       " 'deriv',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandat',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcic',\n",
       " 'aquat',\n",
       " 'ceremoni',\n",
       " '.']"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "[porter.stem(t) for t in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den',\n",
       " ':',\n",
       " 'list',\n",
       " ',',\n",
       " 'strange',\n",
       " 'wom',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'bas',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'suprem',\n",
       " 'execut',\n",
       " 'pow',\n",
       " 'der',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mand',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'som',\n",
       " 'farc',\n",
       " 'aqu',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lancaster.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexedText(object):\n",
    "\n",
    "    def __init__(self, stemmer, text):\n",
    "        self._text = text\n",
    "        self._stemmer = stemmer\n",
    "        self._index = nltk.Index((self._stem(word), i)\n",
    "                                 for (i, word) in enumerate(text))\n",
    "\n",
    "    def concordance(self, word, width=40):\n",
    "        key = self._stem(word)\n",
    "        wc = int(width/4)                # words of context\n",
    "        for i in self._index[key]:\n",
    "            lcontext = ' '.join(self._text[i-wc:i])\n",
    "            rcontext = ' '.join(self._text[i:i+wc])\n",
    "            ldisplay = '{:>{width}}'.format(lcontext[-width:], width=width)\n",
    "            rdisplay = '{:{width}}'.format(rcontext[:width], width=width)\n",
    "            print(ldisplay, rdisplay)\n",
    "\n",
    "    def _stem(self, word):\n",
    "        return self._stemmer.stem(word).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r king ! DENNIS : Listen , strange women lying in ponds distributing swords is no\n",
      " beat a very brave retreat . ROBIN : All lies ! MINSTREL : [ singing ] Bravest of\n",
      "       Nay . Nay . Come . Come . You may lie here . Oh , but you are wounded !   \n",
      "doctors immediately ! No , no , please ! Lie down . [ clap clap ] PIGLET : Well  \n",
      "ere is much danger , for beyond the cave lies the Gorge of Eternal Peril , which \n",
      "   you . Oh ... TIM : To the north there lies a cave -- the cave of Caerbannog --\n",
      "h it and lived ! Bones of full fifty men lie strewn about its lair . So , brave k\n",
      "not stop our fight ' til each one of you lies dead , and the Holy Grail returns t\n"
     ]
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "grail = nltk.corpus.webtext.words('grail.txt')\n",
    "text = IndexedText(porter, grail)\n",
    "text.concordance('lie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'woman',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distributing',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basis',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'government',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'executive',\n",
       " 'power',\n",
       " 'derives',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "[wnl.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"'When I'M a Duchess,' she said to herself, (not in a very hopeful tone\n",
    "though), 'I won't have any pepper in my kitchen AT ALL. Soup does very\n",
    "well without--Maybe it's always pepper that makes people hot-tempered,'...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone\\nthough),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very\\nwell',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r' ', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'[ \\t\\n]+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'When',\n",
       " 'I',\n",
       " 'M',\n",
       " 'a',\n",
       " 'Duchess',\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " 'not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " 'I',\n",
       " 'won',\n",
       " 't',\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " 'Maybe',\n",
       " 'it',\n",
       " 's',\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " 'tempered',\n",
       " '']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'\\W+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " 'I',\n",
       " \"'M\",\n",
       " 'a',\n",
       " 'Duchess',\n",
       " ',',\n",
       " \"'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " ',',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " ')',\n",
       " ',',\n",
       " \"'I\",\n",
       " 'won',\n",
       " \"'t\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " '.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " '-',\n",
       " '-Maybe',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " '-tempered',\n",
       " ',',\n",
       " \"'\",\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\w+|\\S\\w*', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", 'When', \"I'M\", 'a', 'Duchess', ',', \"'\", 'she', 'said', 'to', 'herself', ',', '(', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', \"'\", 'I', \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup', 'does', 'very', 'well', 'without', '--', 'Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', 'hot-tempered', ',', \"'\", '...']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That', 'U.S.A.', 'poster-print', 'costs', '$12.40', '...']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'That U.S.A. poster-print costs $12.40...'\n",
    "pattern = r'''(?x)     # set flag to allow verbose regexps\n",
    "     (?:[A-Z]\\.)+       # abbreviations, e.g. U.S.A.\n",
    "   | \\w+(?:-\\w+)*       # words with optional internal hyphens\n",
    "   | \\$?\\d+(?:\\.\\d+)?%? # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.             # ellipsis\n",
    "   | [][.,;\"'?():-_`]   # these are separate tokens; includes ], [\n",
    " '''\n",
    "nltk.regexp_tokenize(text, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.250994070456922"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.brown.words()) / len(nltk.corpus.brown.sents())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Nonsense!\"',\n",
      " 'said Gregory, who was very rational when anyone else\\nattempted paradox.',\n",
      " '\"Why do all the clerks and navvies in the\\n'\n",
      " 'railway trains look so sad and tired, so very sad and tired?',\n",
      " 'I will\\ntell you.',\n",
      " 'It is because they know that the train is going right.',\n",
      " 'It\\n'\n",
      " 'is because they know that whatever place they have taken a ticket\\n'\n",
      " 'for that place they will reach.',\n",
      " 'It is because after they have\\n'\n",
      " 'passed Sloane Square they know that the next station must be\\n'\n",
      " 'Victoria, and nothing but Victoria.',\n",
      " 'Oh, their wild rapture!',\n",
      " 'oh,\\n'\n",
      " 'their eyes like stars and their souls again in Eden, if the next\\n'\n",
      " 'station were unaccountably Baker Street!\"',\n",
      " '\"It is you who are unpoetical,\" replied the poet Syme.']\n"
     ]
    }
   ],
   "source": [
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
    "sents = nltk.sent_tokenize(text)\n",
    "pprint.pprint(sents[79:89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(text, segs):\n",
    "    words = []\n",
    "    last = 0\n",
    "    for i in range(len(segs)):\n",
    "        if segs[i] == '1':\n",
    "            words.append(text[last:i+1])\n",
    "            last = i+1\n",
    "    words.append(text[last:])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\"\n",
    "segment(text, seg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do',\n",
       " 'you',\n",
       " 'see',\n",
       " 'the',\n",
       " 'kitty',\n",
       " 'see',\n",
       " 'the',\n",
       " 'doggy',\n",
       " 'do',\n",
       " 'you',\n",
       " 'like',\n",
       " 'the',\n",
       " 'kitty',\n",
       " 'like',\n",
       " 'the',\n",
       " 'doggy']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment(text, seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(text, segs):\n",
    "    words = segment(text, segs)\n",
    "    text_size = len(words)\n",
    "    lexicon_size = sum(len(word) + 1 for word in set(words))\n",
    "    return text_size + lexicon_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyou',\n",
       " 'see',\n",
       " 'thekitt',\n",
       " 'y',\n",
       " 'see',\n",
       " 'thedogg',\n",
       " 'y',\n",
       " 'doyou',\n",
       " 'like',\n",
       " 'thekitt',\n",
       " 'y',\n",
       " 'like',\n",
       " 'thedogg',\n",
       " 'y']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\"\n",
    "seg3 = \"0000100100000011001000000110000100010000001100010000001\"\n",
    "segment(text, seg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text, seg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def flip(segs, pos):\n",
    "    return segs[:pos] + str(1-int(segs[pos])) + segs[pos+1:]\n",
    "\n",
    "def flip_n(segs, n):\n",
    "    for i in range(n):\n",
    "        segs = flip(segs, randint(0, len(segs)-1))\n",
    "    return segs\n",
    "\n",
    "def anneal(text, segs, iterations, cooling_rate):\n",
    "    temperature = float(len(segs))\n",
    "    while temperature > 0.5:\n",
    "        best_segs, best = segs, evaluate(text, segs)\n",
    "        for i in range(iterations):\n",
    "            guess = flip_n(segs, round(temperature))\n",
    "            score = evaluate(text, guess)\n",
    "            if score < best:\n",
    "                best, best_segs = score, guess\n",
    "        score, segs = best, best_segs\n",
    "        temperature = temperature / cooling_rate\n",
    "        print(evaluate(text, segs), segment(text, segs))\n",
    "    print()\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "63 ['doyouseet', 'hekitty', 'seeth', 'edoggy', 'doyoulikethekittylike', 'th', 'edoggy']\n",
      "63 ['doyouseet', 'hekitty', 'seeth', 'edoggy', 'doyoulikethekittylike', 'th', 'edoggy']\n",
      "61 ['doyou', 'seeth', 'e', 'kitty', 'seeth', 'edoggy', 'doyou', 'li', 'k', 'ethekittylike', 'th', 'edoggy']\n",
      "59 ['doyou', 'seeth', 'eki', 'tt', 'y', 'seeth', 'edoggy', 'doyou', 'li', 'kethekittyliketh', 'edoggy']\n",
      "55 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'li', 'kethekittyliketh', 'edoggy']\n",
      "53 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'likethekittyliketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0000100001000001000010000010000100000100000100000100000'"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "anneal(text, seg1, 5000, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WecalledhimTortoisebecausehetaughtus.'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silly = ['We', 'called', 'him', 'Tortoise', 'because', 'he', 'taught', 'us', '.']\n",
    "' '.join(silly)\n",
    "';'.join(silly)\n",
    "''.join(silly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "hello world\n",
      "cat\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "word = 'cat'\n",
    "sentence = \"\"\"hello world\"\"\"\n",
    "print(word)\n",
    "print(sentence)\n",
    "print(word)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat -> 3; dog -> 4; snake -> 1; "
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(['dog', 'cat', 'dog', 'cat', 'dog', 'snake', 'dog', 'cat'])\n",
    "for word in sorted(fdist):\n",
    "    print(word, '->', fdist[word], end='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat->3; dog->4; snake->1; "
     ]
    }
   ],
   "source": [
    "for word in sorted(fdist):\n",
    "    print('{}->{};'.format(word, fdist[word]), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat->3;'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}->{};'.format ('cat', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat->\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I want a coffee right now'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{}->'.format('cat'))\n",
    "\n",
    "print('{}'.format(3))\n",
    "\n",
    "'I want a {} right now'.format('coffee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lee wants a sandwich'"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{} wants a {}'.format ('Lee', 'sandwich', 'for lunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from B to A'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'from {1} to {0}'.format('A', 'B') \n",
    "'from B to A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lee wants a sandwich right now\n",
      "Lee wants a spam fritter right now\n",
      "Lee wants a pancake right now\n"
     ]
    }
   ],
   "source": [
    " template = 'Lee wants a {} right now'\n",
    "menu = ['sandwich', 'spam fritter', 'pancake']\n",
    "for snack in menu:\n",
    "    print(template.format(snack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    41'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:6}'.format(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'41    '"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:<6}' .format(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1416'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "'{:.4f}'.format(math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy for 9375 words: 34.1867%'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count, total = 3205, 9375 \n",
    "\"accuracy for {} words: {:.4%}\".format(total, count / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category            can  could    may  might   must   will \n",
      "news                 93     86     66     38     50    389 \n",
      "religion             82     59     78     12     54     71 \n",
      "hobbies             268     58    131     22     83    264 \n",
      "science_fiction      16     49      4     12      8     16 \n",
      "romance              74    193     11     51     45     43 \n",
      "humor                16     30      8      8      9     13 \n"
     ]
    }
   ],
   "source": [
    "def tabulate(cfdist, words, categories):\n",
    "    print('{:16}'.format('Category'), end=' ')                   \n",
    "    for word in words:\n",
    "        print('{:>6}'.format(word), end=' ')\n",
    "    print()\n",
    "    for category in categories:\n",
    "        print('{:16}'.format(category), end=' ')                  \n",
    "        for word in words:                                        \n",
    "            print('{:6}'.format(cfdist[category][word]), end=' ') \n",
    "        print()                                                  \n",
    "\n",
    "from nltk.corpus import brown\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "           (genre, word)\n",
    "          for genre in brown.categories()\n",
    "           for word in brown.words(categories=genre))\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "tabulate(cfd, modals, genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python   '"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:{width}}'.format('Monty Python', width=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('output.txt', 'w')\n",
    "words = set(nltk.corpus.genesis.words('english-kjv.txt'))\n",
    "for word in sorted(words):\n",
    "    print(word, file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2789\n",
      "2789\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "\n",
    "print(str(len(words)))\n",
    "\n",
    "print(str(len(words)), file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (5), all (3), is (2), said (4), and (3), done (4), , (1), more (4), is (2), said (4), than (4), done (4), . (1), "
     ]
    }
   ],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',',\n",
    "          'more', 'is', 'said', 'than', 'done', '.']\n",
    "for word in saying:\n",
    "    print(word, '(' + str(len(word)) + '),', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 all 3 is 2 said 4 and 3 done 4 , 1 more 4 is 2 said 4 than 4\n",
      "done 4 . 1\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "pieces = [\"{} {}\".format(word, len(word)) for word in saying]\n",
    "output = ' '.join(pieces)\n",
    "wrapped = fill(output)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
